# DragonTalker 사용자 매뉴얼

> DragonTalker 사용 방법 및 개발 가이드 상세 안내
> 
> 업데이트: 2026년 2월

---

## 1. 개요

DragonTalker는 딥러닝 기반 말하는 얼굴 생성 시스템입니다. 핵심 기능은 정적 인물 이미지와 오디오 파일을 결합하여说话的동영상을 생성하는 것입니다. 고급 3D 얼굴 재구성 및 이미지 합성 알고리즘을 사용하여 원본 인물의 얼굴 특성을 유지하면서 자연스러운 입술 동기화 및 표정 변화를实现합니다.

### 1.1 적용 시나리오

- **가상 앵커**: 실제 목소리와 표정이 있는 가상 아바타 구성
- **디지털 고객 서비스**:擬人화된 인터랙티브 동영상 생성
- **교육**: 과정을 동영상 형태로 제공
- **더빙**: 캐릭터에 대한 빠른 더빙 애니메이션 생성

---

## 2. 빠른 시작

### 2.1 기본 사용법

```bash
source venv/bin/activate
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results
```

### 2.2 매개변수

| 매개변수 | 설명 | 기본값 |
|---------|------|-------|
| --source_image | 원본 이미지 경로 | 필수 |
| --driven_audio |驱动오디오 경로 | 필수 |
| --result_dir | 출력 폴더 | ./results |
| --enhancer | 얼굴 향상 알고리즘 | gfpgan |
| --outputfps | 프레임 속도 | 25 |

---

## 3. 사양

### 3.1 원본 이미지

- 형식: JPG, PNG
- 해상도: 512×512 이상 권장
- 내용: 정면 얼굴, 선명,遮挡 없음

### 3.2 오디오

- 형식: WAV, MP3
- 길이: 1-60초
- 품질: 선명한 음성

### 3.3 출력 비디오

- 형식: MP4 (H.264)
- 해상도: 256×256 또는 512×512
- 프레임: 25 FPS

---

## 4. 웹 인터페이스

DragonTalker는 그래픽 웹 인터페이스를 제공합니다.

```bash
python app.py
```

브라우저: http://localhost:7860

---

## 5. Python API

### 기본 사용법

```python
from dragon_talker import DragonTalker

model = DragonTalker(
    device='cuda',
    faceid_weight=0.5,
    enhancer='gfpgan'
)

model.load_source('source.jpg')
model.load_audio('audio.wav')

result_path = model.generate(
    output_path='result.mp4',
    preprocess='full',
    fps=25
)

print(f"동영상 저장 위치: {result_path}")
```

---

## 6. FAQ

### 6.1 동영상 품질

**생성된 얼굴이 흐림**

해결: 얼굴 향상 활성화

```bash
python inference.py --enhancer gfpgan ...
```

---

**입술이 오디오와 동기화되지 않음**

원인: 오디오 품질 낮음 또는 말하기 속도 빠름

해결: 오디오 전처리, 샘플레이트 증가

---

### 6.2 성능

**GPU 메모리 부족**

해결:
1. 출력 해상도 축소
2. 향상 기능 비활성화
3. CPU 모드 사용

---

## 7. 참고 자료

- 데모: https://huggingface.co/spaces/dragon-talker
- GitHub: https://github.com/your-repo/DragonTalker
