# SadTalker Usage Guide

SadTalker is an AI model that generates realistic talking head videos from a single image and audio input.

## Quick Start

### Basic Inference

```bash
python inference.py \
  --source_image /path/to/image.jpg \
  --driven_audio /path/to/audio.wav \
  --result_dir ./results \
  --preprocess full \
  --enhancer gfpgan
```

### Parameters

| Parameter | Description | Default |
|-----------|-------------|---------|
| `--source_image` | Input portrait image | Required |
| `--driven_audio` | Input audio file | Required |
| `--result_dir` | Output directory | ./results |
| `--preprocess` | Image preprocessing: crop, resize, full | full |
| `--enhancer` | Face enhancer: gfpgan, RestoreFormer | None |
| `--pose_style` | Pose style 0-45 | 0 |
| `--batch_size` | Batch size | 1 |
| `--size` | Image size | 256 |
| `--expression_scale` | Expression intensity | 1.0 |

## Usage Examples

### Generate Video from Image and Audio

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results \
  --preprocess full \
  --enhancer gfpgan
```

### Using Specific Pose Style

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --pose_style 5
```

### Batch Processing

```bash
# Process multiple audio files with same image
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/audio_folder \
  --result_dir results
```

## Python API

### Basic Usage

```python
from inference import SadTalker

# Initialize
sadtalker = SadTalker()

# Generate video
video_path = sadtalker.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="full",
    enhancer="gfpgan"
)

print(f"Video saved to: {video_path}")
```

### Advanced Usage

```python
from inference import SadTalker
import torch

# Initialize with custom settings
sadtalker = SadTalker(
    checkpoint_path="checkpoints/SadTalker.pth",
    config_path="config/SadTalker.yaml",
    device="cuda" if torch.cuda.is_available() else "cpu"
)

# Generate with specific settings
video_path = sadtalker.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="crop",
    pose_style=10,
    expression_scale=1.2,
    output_video="output.mp4"
)
```

## Web Interface

### Running Web Demo

```bash
python app.py
```

Then open browser at http://localhost:8888

### Web Interface Features
- Drag and drop image upload
- Audio file selection
- Preview generation
- Adjust parameters
- Download results

## Model Options

### Face Enhancers

| Enhancer | Description | Quality |
|----------|-------------|---------|
| None | No enhancement | Basic |
| gfpgan | GFP-GAN | Good |
| RestoreFormer | RestoreFormer++ | Best |

### Preprocessing Modes

| Mode | Description |
|------|-------------|
| crop | Center crop face |
| resize | Resize to target size |
| full | Full processing pipeline |

## Performance Tips

### Faster Inference
- Use FP16 precision: `--half`
- Reduce image size: `--size 256`
- Disable enhancer: Remove `--enhancer`

### Better Quality
- Use high resolution: `--size 512`
- Enable GFPGAN: `--enhancer gfpgan`
- Adjust expression: `--expression_scale 1.2`

### GPU Memory Optimization
- Reduce batch size
- Use CPU offloading
- Enable gradient checkpointing

## Output Format

Generated videos are saved as:
- MP4 format
- H.264 codec
- 25 FPS
- Same resolution as input image

## Troubleshooting

### Video Too Dark/Bright
- Adjust expression_scale parameter
- Check audio quality

### Lips Not Synced
- Ensure audio and video are properly aligned
- Check audio has clear speech

### Face Distorted
- Use higher resolution image
- Try different preprocessing mode

## Related Links

- [GitHub](https://github.com/OpenTalker/SadTalker)
- [HuggingFace](https://huggingface.co/spaces/fffilo/SadTalker)
- [Paper](https://arxiv.org/abs/2303.17550)
