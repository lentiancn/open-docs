# Hadoop 安装指南

> Hadoop 安装和配置完整指南

---

## 环境要求

| 资源 | 最低配置 | 推荐配置 |
|------|----------|----------|
| CPU | 2 核 | 4 核及以上 |
| 内存 | 4 GB | 8 GB 及以上 |
| 磁盘 | 50 GB | 100 GB 及以上 |
| OS | Ubuntu、CentOS、RHEL | - |

---

## 安装方式

### 1. 单机模式安装

```bash
# 下载 Hadoop
wget https://dlcdn.apache.org/hadoop/common/hadoop-3.3.6/hadoop-3.3.6.tar.gz

# 解压
tar -xzf hadoop-3.3.6.tar.gz -C /usr/local/

# 配置环境变量
export HADOOP_HOME=/usr/local/hadoop-3.3.6
export PATH=$PATH:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
```

### 2. 伪分布式模式

```bash
# 配置 core-site.xml
vim $HADOOP_HOME/etc/hadoop/core-site.xml

<configuration>
    <property>
        <name>fs.defaultFS</name>
        <value>hdfs://localhost:9000</value>
    </property>
</configuration>

# 配置 hdfs-site.xml
vim $HADOOP_HOME/etc/hadoop/hdfs-site.xml

<configuration>
    <property>
        <name>dfs.replication</name>
        <value>1</value>
    </property>
</configuration>

# 格式化 NameNode
hdfs namenode -format

# 启动 HDFS
start-dfs.sh
```

### 3. 完全分布式模式

需要配置多台机器的 SSH 无密码访问，以及以下配置文件：
- core-site.xml
- hdfs-site.xml
- yarn-site.xml
- mapred-site.xml

---

## 验证安装

```bash
# 查看版本
hadoop version

# 运行示例
hadoop jar $HADOOP_HOME/share/hadoop/mapreduce/hadoop-mapreduce-examples-3.3.6.jar pi 2 5
```

---

## 常用命令

```bash
# 启动 HDFS
start-dfs.sh

# 停止 HDFS
stop-dfs.sh

# 查看文件列表
hdfs dfs -ls /

# 创建目录
hdfs dfs -mkdir -p /user/hadoop

# 上传文件
hdfs dfs -put localfile /user/hadoop/

# 下载文件
hdfs dfs -get /user/hadoop/localfile
```
