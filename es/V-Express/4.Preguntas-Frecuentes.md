# V-Express Preguntas Frecuentes

## Preguntas Generales

### ¿Qué es V-Express?
V-Express es un modelo de IA que genera videos de cabeza parlante a partir de una imagen de retrato y entrada de audio. Crea animaciones faciales realistas con sincronización de labios.

### ¿V-Express es gratuito?
V-Express es de código abierto para propósitos de investigación. Consulta la LICENSE para términos comerciales.

### ¿Qué diferencia V-Express de otros generadores?
V-Express usa:
- Decodificación progresiva condicional difusa
- Módulo VQ aware de debilidad
- Condicionamiento multinivel
- Mejor manejo de expresiones débiles

## Preguntas de Instalación

### ¿Cuáles son los requisitos?
```bash
# Entorno Python
conda create -n vexpress python=3.8
conda activate vexpress

# Instalar dependencias
pip install torch torchvision
pip install opencv-python
pip install librosa
pip install -r requirements.txt
```

### ¿Cómo descargo los modelos?
```bash
bash scripts/download_models.sh
```

### ¿Necesito una GPU potente?
Sí, una GPU con 8GB+ VRAM es recomendada. Más VRAM permite mejor calidad y procesamiento más rápido.

## Preguntas de Uso

### ¿Cómo genero un video parlante?
```bash
python inference.py --reference_image path/to/image.jpg --audio path/to/audio.wav --output output.mp4
```

### ¿Qué formatos de imagen son soportados?
- JPG/JPEG
- PNG
- BMP
- WebP

### ¿Qué formatos de audio son soportados?
- WAV (recomendado)
- MP3
- FLAC

### ¿Cuánto tiempo toma generar un video?
El tiempo de procesamiento depende de:
- Longitud del video
- Rendimiento GPU
- Resolución de salida
- Configuración de calidad

Típico: 1-5 minutos por segundo de video en GPU.

### ¿Puedo usar un video de referencia?
Sí, proporciona un video de referencia para patrones de movimiento:
```bash
python inference.py \
    --reference_image path/to/image.jpg \
    --audio path/to/audio.wav \
    --reference_video path/to/video.mp4 \
    --output output.mp4
```

## Solución de Problemas

### Mala sincronización de labios
- Usa audio de alta calidad sin ruido de fondo
- Asegura habla clara en el audio

### Distorsión de identidad
- Usa imagen de alta resolución y frontal
- Evita fotos muy editadas
- Asegura buena iluminación en imagen fuente

### Artefactos en salida
- Reduce resolución de salida
- Verifica instalación correcta de modelos
- Actualiza drivers GPU

### Errores de memoria
- Reduce tamaño de batch
- Baja resolución de salida
- Usa gradient checkpointing
- Cierra otras aplicaciones GPU

## Preguntas Avanzadas

### ¿Cómo controlo la fuerza de expresión?
```bash
python inference.py \
    --reference_image path/to/image.jpg \
    --audio path/to/audio.wav \
    --expression_strength 0.7 \
    --output output.mp4
```

### ¿Puedo generar con poses específicas?
Usa control de pose o proporciona un video de referencia con poses deseadas.

### ¿Qué es el Módulo VQ aware de debilidad?
Es un componente que maneja expresiones desafiantes aprendiendo de señales débiles en los datos de entrenamiento.

## Mejores Prácticas

1. Usa imágenes de retrato claras y de alta resolución
2. Usa audio limpio sin ruido de fondo
3. Proporciona video de referencia para mejor movimiento
4. Ajusta parámetros para casos de uso específicos
5. Usa iluminación consistente en imágenes fuente

## Consideraciones Éticas

- Obtén consentimiento antes de usar imágenes de otros
- Se transparente sobre contenido generado por IA
- Sigue leyes y regulaciones aplicables
- Usa de manera responsable para prevenir mal uso

## Recursos

- Repositorio GitHub: https://github.com/TencentARC/V-Express
- Paper: V-Express paper
- Comunidad: GitHub Issues
