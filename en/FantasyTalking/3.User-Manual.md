# FantasyTalking User Manual

Detailed usage guide and examples.

## Basic Usage

### Generate Video

```bash
python inference.py \
  --source_image face.jpg \
  --audio speech.wav \
  --output output.mp4
```

### Parameters

| Parameter | Short | Description | Default |
|-----------|-------|-------------|---------|
| --source_image | -s | Input image path | Required |
| --audio | -a | Input audio file | Required |
| --output | -o | Output video path | output.mp4 |
| --face_enhancer | -f | Face enhancer model | None |
| --max_frames | -m | Max frames | 300 |
| --fps | -fps | Output FPS | 25 |

### Full Example

```bash
python inference.py \
  --source_image photos/person1.jpg \
  --audio audio/speech.wav \
  --output results/video1.mp4 \
  --face_enhancer realusf \
  --fps 30
```

## Advanced Usage

### Python API

```python
from fantasytalking import FantasyTalking

# Initialize model
ft = FantasyTalking(
    checkpoint_path="./models/checkpoint.pth",
    face_enhancer="realusf"
)

# Generate video
ft.generate(
    source_image="face.jpg",
    audio="speech.wav",
    output="output.mp4"
)
```

### Batch Processing

```python
import os
from fantasytalking import FantasyTalking

ft = FantasyTalking()

images_dir = "./images"
audio_dir = "./audio"
output_dir = "./output"

for image_file in os.listdir(images_dir):
    for audio_file in os.listdir(audio_dir):
        output_name = f"{image_file}_{audio_file}.mp4"
        ft.generate(
            source_image=os.path.join(images_dir, image_file),
            audio=os.path.join(audio_dir, audio_file),
            output=os.path.join(output_dir, output_name)
        )
```

### Web API Service

```bash
# Start API service
python api.py --port 8080
```

Example call:

```bash
curl -X POST http://localhost:8080/generate \
  -F "image=@face.jpg" \
  -F "audio=@speech.wav" \
  -o output.mp4
```

## Input Requirements

### Image Format

- **Supported Formats**: JPG, PNG, BMP
- **Recommended Resolution**: 512x512 or higher
- **Face Requirements**:
  - Front-facing clear photo works best
  - Face should occupy 50%+ of the image
  - Good lighting, natural expression

### Audio Format

- **Supported Formats**: WAV, MP3, FLAC
- **Sample Rate**: 16000 Hz or 44100 Hz
- **Duration**: 1-60 seconds recommended
- **Language**: Multi-language auto-detection supported

## Output Settings

### Resolution

```bash
# Set output resolution
python inference.py --source_image face.jpg --audio speech.wav --output output.mp4 --size 512
```

Supported resolutions: 256, 512, 768, 1024

### FPS

```bash
# Set frame rate
python inference.py --source_image face.jpg --audio speech.wav --output output.mp4 --fps 30
```

### Video Format

Supported output formats: MP4 (H.264), AVI, MOV

## Performance Optimization

### GPU Acceleration

Make sure to use CUDA:

```python
ft = FantasyTalking(device="cuda")
```

### Batch Processing

Use batch processing for multiple files:

```python
ft.batch_generate(image_list, audio_list, output_dir)
```

### Mixed Precision

Enable FP16 acceleration:

```python
ft = FantasyTalking(precision="fp16")
```

## Common Issues

### Video generation failed?

1. Check if input image contains a face
2. Confirm audio format is correct
3. Ensure sufficient VRAM

### Face deformed?

1. Use clearer input images
2. Adjust face keypoint parameters

### Lips not synced?

1. Ensure audio is clear
2. Adjust sync parameters

## Best Practices

1. **Choose suitable images**: Front-facing, high-resolution, even lighting
2. **Prepare clear audio**: No noise, moderate speaking speed
3. **Set parameters reasonably**: Adjust resolution and FPS as needed
4. **Use face enhancement**: Improves output quality

## Next Steps

- FAQ: See 4.FAQ.md
