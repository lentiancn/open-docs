# V-Express Guía de Uso

V-Express genera videos de cabezas parlantes bajo el control de una imagen de referencia, audio y secuencias V-Kps.

## Inicio Rápido

### Comando Básico

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/aud.mp3" \
  --kps_path "./test_samples/short_case/AOC/kps.pth" \
  --output_path "./output/result.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25
```

## Parámetros del Comando

### Parámetros de Entrada

| Parámetro | Descripción | Requerido |
|-----------|-------------|-----------|
| `--reference_image_path` | Ruta de imagen de retrato de referencia | Sí |
| `--audio_path` | Ruta del archivo de audio de entrada (MP3/WAV) | Sí |
| `--kps_path` | Ruta del archivo de secuencia V-Kps | No |
| `--output_path` | Ruta del video de salida | Sí |

### Estrategias de Reorientación

| Estrategia | Descripción |
|------------|-------------|
| `no_retarget` | Imagen y video de la misma persona (mejores resultados) |
| `fix_face` | Cualquier imagen y audio (solo sincronización de labios) |
| `offset_retarget` | Imagen de persona diferente con ligero movimiento facial |
| `naive_retarget` | Imagen de persona diferente con reorientación completa |

### Parámetros de Procesamiento

| Parámetro | Descripción | Valor Predeterminado |
|-----------|-------------|----------------------|
| `--retarget_strategy` | Estrategia de reorientación facial | no_retarget |
| `--num_inference_steps` | Número de pasos de inferencia | 25 |
| `--reference_attention_weight` | Peso de imagen de referencia (0.9-1.0) | 1.0 |
| `--audio_attention_weight` | Peso de audio (1.0-3.0) | 1.0 |
| `--save_gpu_memory` | Habilitar modo de ahorro de memoria | False |

### Rangos de Parámetros Recomendados

- `reference_attention_weight`: 0.9-1.0
- `audio_attention_weight`: 1.0-3.0

## Ejemplos de Uso

### Escenario 1: Misma Persona (Mejor Calidad)

Cuando tiene una imagen de la persona A y un video hablando de la persona A:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/aud.mp3" \
  --kps_path "./test_samples/short_case/AOC/kps.pth" \
  --output_path "./output/talk_AOC_no_retarget.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25
```

### Escenario 2: Cualquier Audio (Solo Sincronización de Labios)

Cuando solo tiene una imagen y cualquier audio hablado:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/tys/ref.jpg" \
  --audio_path "./test_samples/short_case/tys/aud.mp3" \
  --output_path "./output/talk_tys_fix_face.mp4" \
  --retarget_strategy "fix_face" \
  --num_inference_steps 25
```

### Escenario 3: Persona Diferente con Movimiento Facial

Cuando tiene una imagen de persona A y video hablado de persona B:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/tys/ref.jpg" \
  --audio_path "./test_samples/short_case/tys/aud.mp3" \
  --kps_path "./test_samples/short_case/tys/kps.pth" \
  --output_path "./output/talk_tys_offset_retarget.mp4" \
  --retarget_strategy "offset_retarget" \
  --num_inference_steps 25
```

### Escenario 4: Pesos de Atención Personalizados

Ajustar pesos para diferentes efectos:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/10/ref.jpg" \
  --audio_path "./test_samples/short_case/10/aud.mp3" \
  --output_path "./output/talk_10_weighted.mp4" \
  --retarget_strategy "fix_face" \
  --reference_attention_weight 0.95 \
  --audio_attention_weight 3.0
```

### Escenario 5: Audio Largo (Optimizado para Memoria)

Para archivos de audio más largos (30+ segundos):

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/long_audio.mp3" \
  --kps_path "./test_samples/short_case/AOC/AOC_raw_kps.pth" \
  --output_path "./output/long_video.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25 \
  --reference_attention_weight 1.0 \
  --audio_attention_weight 1.0 \
  --save_gpu_memory
```

## Extraer Secuencia V-Kps

Si tiene un video objetivo, extraiga la secuencia V-Kps:

```bash
python scripts/extract_kps_sequence_and_audio.py \
  --video_path "./test_samples/short_case/AOC/gt.mp4" \
  --kps_sequence_save_path "./test_samples/short_case/AOC/kps.pth" \
  --audio_save_path "./test_samples/short_case/AOC/aud.mp3"
```

## Requisitos de Entrada

### Imagen de Referencia

- Formato: JPG, PNG
- Resolución: 512x512 o superior (cuadrada recomendada)
- Cara: Frontal, clara, sin oclusión
- Fondo: Simple preferido

### Audio

- Formato: MP3, WAV
- Duración: 1-60 segundos (más largo con --save_gpu_memory)
- Tasa de muestreo: 16000-48000 Hz
- Voz: Clara, ruido mínimo

### Secuencia V-Kps

- Formato: PyTorch (.pth)
- Generado del video objetivo usando el script proporcionado

## Salida

### Formato de Video

- Formato: MP4
- Códec: H.264
- Resolución: Misma que entrada o predeterminada 512x512
- Cuadros por segundo: 24-30

## Solución de Problemas

### Mala Calidad de Video

**Soluciones:**
- Usar imagen de referencia de mayor calidad (512x512+)
- Aumentar pasos de inferencia (25-30)
- Ajustar pesos de atención

### Problemas de Sincronización de Labios

**Soluciones:**
- Aumentar `audio_attention_weight` (1.5-3.0)
- Usar audio de mayor calidad
- Asegurarse de que el audio tenga voz clara

### Deformación Facial

**Soluciones:**
- Usar pose similar en el video objetivo
- Probar diferente estrategia de reorientación
- Usar no_retarget para la misma persona

### GPU Sin Memoria

**Soluciones:**
- Habilitar `--save_gpu_memory`
- Reducir pasos de inferencia
- Usar audio más corto

### Procesamiento Muy Lento

**Soluciones:**
- Reducir pasos de inferencia (15-20)
- Usar modelo más pequeño
- Deshabilitar funciones no utilizadas

## Mejores Prácticas

1. **Videos de la Misma Persona**: Use la estrategia `no_retarget` para mejores resultados
2. **Persona Diferente**: Elija video objetivo con pose similar a la cara de referencia
3. **Calidad de Imagen**: Use imágenes de cara cuadradas claras de 512x512
4. **Calidad de Audio**: Use audio con voz clara
5. **Ajuste de Pesos**: Ajuste los pesos de atención para diferentes efectos

## Enlaces Relacionados

- [GitHub](https://github.com/tencent-ailab/V-Express)
- [HuggingFace](https://huggingface.co/tk93/V-Express)
- [Artículo](https://arxiv.org/abs/2406.02511)
- [Página del Proyecto](https://tenvence.github.io/p/v-express/)
