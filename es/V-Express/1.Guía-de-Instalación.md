# V-Express Guía de Instalación

V-Express es un método de generación de videos de retrato desarrollado por Tencent AI Lab. Genera videos de cabezas parlantes bajo el control de una imagen de referencia, audio y secuencias V-Kps.

## Versión General

| Versión | Estado | Descripción |
|---------|--------|-------------|
| V-Express 1.x | Actual | Versión principal |

## Requisitos del Sistema

### Requisitos de Hardware

| Componente | Mínimo | Recomendado |
|------------|--------|-------------|
| GPU | NVIDIA 16GB VRAM | NVIDIA 24GB+ VRAM |
| RAM | 16GB | 32GB+ |
| Almacenamiento | 50GB | 100GB+ |
| CUDA | 11.8+ | 12.1+ |

### Requisitos de Software

| Software | Versión | Notas |
|----------|---------|-------|
| Python | 3.8 - 3.10 | Recomendado 3.9 |
| CUDA | 11.8+ | Aceleración GPU requerida |
| cuDNN | 8.5+ | Requerido para CUDA |
| ffmpeg | Latest | Procesamiento de video requerido |

## Instalación en Linux/Ubuntu

### Paso 1: Instalar Dependencias del Sistema

```bash
# Actualizar sistema
sudo apt update && sudo apt upgrade -y

# Instalar Python y herramientas de desarrollo
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Instalar bibliotecas del sistema
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# Instalar ffmpeg
sudo apt install ffmpeg

# Instalar git-lfs
sudo apt install git-lfs
```

### Paso 2: Clonar Proyecto

```bash
git clone https://github.com/tencent-ailab/V-Express.git
cd V-Express
```

### Paso 3: Crear Entorno Virtual

```bash
python3.9 -m venv venv
source venv/bin/activate

# Verificar versión de Python
python --version
```

### Paso 4: Instalar PyTorch

```bash
# Versión CUDA 11.8
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Verificar instalación
python -c "import torch; print(torch.cuda.is_available())"
```

### Paso 5: Instalar Dependencias

```bash
pip install -r requirements.txt
```

### Paso 6: Descargar Modelos

```bash
# Instalar git-lfs
git lfs install

# Clonar modelos desde HuggingFace
git clone https://huggingface.co/tk93/V-Express

# Mover modelos a la ubicación correcta
mv V-Express/model_ckpts model_ckpts
mv V-Express/*.bin model_ckpts/v-express
```

Alternativamente, descargar modelos individualmente:

```bash
# Crear directorio de modelos
mkdir -p model_ckpts

# Descargar modelos requeridos:
# - stabilityai/sd-vae-ft-mse
# - run wayml/stable-diffusion-v1-5 (solo config unet)
# - facebook/wav2vec2-base-960h
# - insightface/buffalo_l
```

## Instalación en Windows

### Paso 1: Instalar Python

1. Descargar Python 3.9 desde python.org
2. Marcar "Add Python to PATH" durante la instalación
3. Verificar: `python --version`

### Paso 2: Instalar CUDA

1. Descargar CUDA 11.8 desde el sitio web de NVIDIA
2. Instalar con configuración predeterminada
3. Descargar e instalar cuDNN 8.9

### Paso 3: Clonar y Configurar

```powershell
git clone https://github.com/tencent-ailab/V-Express.git
cd V-Express

python -m venv venv
venv\Scripts\activate
```

### Paso 4: Instalar Dependencias

```powershell
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Paso 5: Descargar Modelos

Descargar modelos desde HuggingFace y colocarlos en el directorio `model_ckpts/`.

## Instalación en macOS

### Paso 1: Instalar Dependencias

```bash
# Instalar Homebrew (si no está instalado)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Instalar Python y ffmpeg
brew install python@3.9 ffmpeg git git-lfs
```

### Paso 2: Configurar

```bash
git clone https://github.com/tencent-ailab/V-Express.git
cd V-Express

python3.9 -m venv venv
source venv/bin/activate

# Instalar PyTorch (solo CPU en macOS)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Nota: macOS solo soporta modo CPU, no puede usar aceleración GPU.

## Verificar Instalación

```bash
# Probar funcionalidad básica
python inference.py --help
```

## Problemas Comunes

### Memoria CUDA Agotada

**Soluciones:**
- Reducir pasos de inferencia: `--num_inference_steps 15`
- Habilitar ahorro de memoria: `--save_gpu_memory`
- Usar menor resolución

### Bibliotecas Faltantes (Windows)

**Soluciones:**
- Instalar Visual C++ Redistributable 2015-2022
- Agregar CUDA al PATH del sistema

### Error al Descargar Modelos

**Soluciones:**
- Usar VPN o proxy
- Descargar manualmente desde HuggingFace
- Verificar conexión de red

### ffmpeg No Encontrado

**Soluciones:**
- Linux: `sudo apt install ffmpeg`
- Windows: Agregar ffmpeg al PATH
- macOS: `brew install ffmpeg`

## Notas Importantes

1. **Reorientación de Cara**: Cuando el video objetivo no es la misma persona que la imagen de referencia, la reorientación facial es importante. Elija un video objetivo con pose más similar a la cara de referencia para mejores resultados.

2. **Soporte de Idiomas**: El modelo funciona mejor en inglés; otros idiomas no han sido probados en detalle.

3. **Calidad de Imagen**: Use imágenes de cara cuadradas claras con resolución de al menos 512x512.

## Enlaces Relacionados

- [Repositorio GitHub](https://github.com/tencent-ailab/V-Express)
- [Modelos HuggingFace](https://huggingface.co/tk93/V-Express)
- [Artículo](https://arxiv.org/abs/2406.02511)
- [Página del Proyecto](https://tenvence.github.io/p/v-express/)
