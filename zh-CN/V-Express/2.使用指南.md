# V-Express 使用指南

V-Express 在参考图像、音频和 V-Kps 序列的控制下生成说话头像视频。

## 快速开始

### 基本命令

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/aud.mp3" \
  --kps_path "./test_samples/short_case/AOC/kps.pth" \
  --output_path "./output/result.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25
```

## 命令参数

### 输入参数

| 参数 | 说明 | 必需 |
|------|------|------|
| `--reference_image_path` | 参考人像图像路径 | 是 |
| `--audio_path` | 输入音频文件路径 (MP3/WAV) | 是 |
| `--kps_path` | V-Kps 序列文件路径 | 否 |
| `--output_path` | 输出视频路径 | 是 |

### 重定向策略

| 策略 | 说明 |
|------|------|
| `no_retarget` | 同一个人的图像和视频（最佳效果） |
| `fix_face` | 任意图像和音频（仅唇同步） |
| `offset_retarget` | 不同人的图像，带轻微面部运动 |
| `naive_retarget` | 不同人的图像，完全重定向 |

### 处理参数

| 参数 | 说明 | 默认值 |
|------|------|--------|
| `--retarget_strategy` | 人脸重定向策略 | no_retarget |
| `--num_inference_steps` | 推理步数 | 25 |
| `--reference_attention_weight` | 参考图像权重 (0.9-1.0) | 1.0 |
| `--audio_attention_weight` | 音频权重 (1.0-3.0) | 1.0 |
| `--save_gpu_memory` | 启用内存节省模式 | False |

## 使用示例

### 场景 1：同一个人（最佳质量）

当你有 A 的图像和 A 的说话视频时：

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/aud.mp3" \
  --kps_path "./test_samples/short_case/AOC/kps.pth" \
  --output_path "./output/talk_AOC_no_retarget.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25
```

### 场景 2：任意音频（仅唇同步）

当你只有图像和任意说话音频时：

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/tys/ref.jpg" \
  --audio_path "./test_samples/short_case/tys/aud.mp3" \
  --output_path "./output/talk_tys_fix_face.mp4" \
  --retarget_strategy "fix_face" \
  --num_inference_steps 25
```

### 场景 3：不同人

当你的图像是 A，视频是 B 时：

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/tys/ref.jpg" \
  --audio_path "./test_samples/short_case/tys/aud.mp3" \
  --kps_path "./test_samples/short_case/tys/kps.pth" \
  --output_path "./output/talk_tys_offset_retarget.mp4" \
  --retarget_strategy "offset_retarget" \
  --num_inference_steps 25
```

### 场景 4：自定义权重

调整权重以获得不同效果：

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/10/ref.jpg" \
  --audio_path "./test_samples/short_case/10/aud.mp3" \
  --output_path "./output/talk_10_weighted.mp4" \
  --retarget_strategy "fix_face" \
  --reference_attention_weight 0.95 \
  --audio_attention_weight 3.0
```

## 提取 V-Kps 序列

如果你有目标视频，提取 V-Kps 序列：

```bash
python scripts/extract_kps_sequence_and_audio.py \
  --video_path "./test_samples/short_case/AOC/gt.mp4" \
  --kps_sequence_save_path "./test_samples/short_case/AOC/kps.pth" \
  --audio_save_path "./test_samples/short_case/AOC/aud.mp3"
```

## 输入要求

### 参考图像

- 格式：JPG、PNG
- 分辨率：512x512 或更高（正方形推荐）
- 人脸：正面、清晰、无遮挡

### 音频

- 格式：MP3、WAV
- 时长：1-60 秒
- 采样率：16000-48000 Hz

## 输出

### 视频格式

- 格式：MP4
- 分辨率：512x512
- 帧率：24-30

## 故障排除

### 视频质量差

**解决方案：**
- 使用更高质量的参考图像
- 增加推理步数（25-30）
- 调整注意力权重

### 嘴唇不同步

**解决方案：**
- 增加 `audio_attention_weight` (1.5-3.0)
- 使用更高质量的音频

### GPU 内存不足

**解决方案：**
- 启用 `--save_gpu_memory`
- 减少推理步数

## 最佳实践

1. **同一个人**：使用 `no_retarget` 策略获得最佳效果
2. **不同人**：选择与参考人脸姿势相似的目标视频
3. **图像质量**：使用清晰的 512x512 正方形人脸图像

## 相关链接

- [GitHub](https://github.com/tencent-ailab/V-Express)
- [HuggingFace](https://huggingface.co/tk93/V-Express)
- [论文](https://arxiv.org/abs/2406.02511)
