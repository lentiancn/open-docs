# FantasyTalking - 사용자 매뉴얼

상세 사용 방법과 예제.

## 기본 사용법

### 비디오 생성

```bash
python inference.py \
  --source_image face.jpg \
  --audio speech.wav \
  --output output.mp4
```

### 매개변수

| 매개변수 | 약어 | 설명 | 기본값 |
|----------|------|------|--------|
| --source_image | -s | 입력 이미지 경로 | 필수 |
| --audio | -a | 입력 오디오 파일 | 필수 |
| --output | -o | 출력 비디오 경로 | output.mp4 |
| --face_enhancer | -f | 얼굴 향상 모델 | None |
| --max_frames | -m | 최대 프레임 | 300 |
| --fps | -fps | 출력 FPS | 25 |

### 전체 예제

```bash
python inference.py \
  --source_image photos/person1.jpg \
  --audio audio/speech.wav \
  --output results/video1.mp4 \
  --face_enhancer realusf \
  --fps 30
```

## 고급 사용법

### Python API

```python
from fantasytalking import FantasyTalking

# 모델 초기화
ft = FantasyTalking(
    checkpoint_path="./models/checkpoint.pth",
    face_enhancer="realusf"
)

# 비디오 생성
ft.generate(
    source_image="face.jpg",
    audio="speech.wav",
    output="output.mp4"
)
```

### 배치 처리

```python
import os
from fantasytalking import FantasyTalking

ft = FantasyTalking()

images_dir = "./images"
audio_dir = "./audio"
output_dir = "./output"

for image_file in os.listdir(images_dir):
    for audio_file in os.listdir(audio_dir):
        output_name = f"{image_file}_{audio_file}.mp4"
        ft.generate(
            source_image=os.path.join(images_dir, image_file),
            audio=os.path.join(audio_dir, audio_file),
            output=os.path.join(output_dir, output_name)
        )
```

### 웹 API 서비스

```bash
# API 서비스 시작
python api.py --port 8080
```

호출 예제:

```bash
curl -X POST http://localhost:8080/generate \
  -F "image=@face.jpg" \
  -F "audio=@speech.wav" \
  -o output.mp4
```

## 입력 요구사항

### 이미지 형식

- **지원 형식**: JPG, PNG, BMP
- **권장 해상도**: 512x512 이상
- **얼굴 요구사항**:
  - 전면 واضح한 사진이 가장 잘 작동
  - 얼굴이 이미지의 50% 이상을 차지해야 함
  - 좋은 조명, 자연스러운 표정

### 오디오 형식

- **지원 형식**: WAV, MP3, FLAC
- **샘플 레이트**: 16000 Hz 또는 44100 Hz
- **길이**: 1-60초 권장
- **언어**: 다국어 자동 감지 지원

## 출력 설정

### 해상도

```bash
# 출력 해상도 설정
python inference.py --source_image face.jpg --audio speech.wav --output output.mp4 --size 512
```

지원 해상도: 256, 512, 768, 1024

### FPS

```bash
# 프레임 레이트 설정
python inference.py --source_image face.jpg --audio speech.wav --output output.mp4 --fps 30
```

### 비디오 형식

지원 출력 형식: MP4 (H.264), AVI, MOV

## 성능 최적화

### GPU 가속

CUDA를 사용하도록 확인:

```python
ft = FantasyTalking(device="cuda")
```

### 배치 처리

여러 파일에 대해 배치 처리 사용:

```python
ft.batch_generate(image_list, audio_list, output_dir)
```

### 혼합 정밀도

FP16 가속 활성화:

```python
ft = FantasyTalking(precision="fp16")
```

## 일반적인 문제

### 비디오 생성 실패?

1. 입력 이미지에 얼굴이 포함되어 있는지 확인
2. 오디오 형식이 올바른지 확인
3. 충분한 VRAM이 있는지 확인

### 얼굴 변형?

1. 더 선명한 입력 이미지 사용
2 얼굴 키포인트 매개변수 조정

### 입술 동기화 안됨?

1. 오디오가 선명하지 않은지 확인
2. 동기화 매개변수 조정

## 모범 사례

1. **적절한 이미지 선택**: 전면, 고해상도, 고른 조명
2. **선명한 오디오 준비**: 노이즈 없음, 중간 말하기 속도
3. **매개변수 합리적으로 설정**: 필요에 따라 해상도 및 FPS 조정
4. **얼굴 향상 사용**: 출력 품질 향상

## 다음 단계

- FAQ: ./4.FAQ.md 참조
