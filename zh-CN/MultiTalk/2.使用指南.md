# MultiTalk 使用指南

本指南介绍如何使用 MultiTalk 生成多说话人音频内容。

## 快速开始

### 基本用法

```bash
python inference.py \
  --text "大家好，欢迎使用 MultiTalk。" \
  --speakers speaker1,speaker2 \
  --output result.wav
```

## 输入要求

### 文本要求

- 语言：多语言支持
- 格式：纯文本
- 长度：无严格限制

### 说话人配置

在 `speakers.yaml` 中定义说话人：

```yaml
speakers:
  speaker1:
    voice_id: "voice_001"
    language: "zh"
  speaker2:
    voice_id: "voice_002"
    language: "zh"
```

## 高级用法

### 自定义语音 ID

```bash
python inference.py \
  --text "这是一个自定义语音演示。" \
  --voice_ids voice001,voice002 \
  --output output.wav
```

### 调整语速

```bash
python inference.py \
  --text "慢速语音示例。" \
  --speakers speaker1 \
  --speed 0.8 \
  --output slow.wav
```

### 批量处理

```bash
python batch_inference.py \
  --text_file texts.txt \
  --output_dir output/
```

## 配置

### 配置文件

编辑 `config.yaml`:

```yaml
inference:
  sample_rate: 22050
  speed: 1.0
  
model:
  checkpoint: "checkpoints/multitalk.pth"
```

## 最佳实践

### 1. 使用合适的语音 ID

选择与说话人特征匹配的语音 ID。

### 2. 匹配语言

确保文本语言与语音语言一致。

### 3. 优化语速

调整语速以获得自然的输出效果。

## 故障排除

### 音频质量差？

尝试不同的语音 ID。

### 语速问题？

逐步调整语速参数。

## 相关资源

- [GitHub](https://github.com/MultiTalk/MultiTalk)
