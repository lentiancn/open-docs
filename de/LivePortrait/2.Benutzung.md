# LivePortrait Benutzerhandbuch

LivePortrait ist ein effizientes Porträt-Animationsframework, das statische Porträts mit Bewegungen aus Steuerungsvideos animiert. Es unterstützt Stitching- und Retargeting-Kontrolle.

## Schnellstart

### Grundbefehl

```bash
# Video-gesteuerte Animation
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir ./results
```

### Mit Stitching

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir ./results \
  --stitching
```

### Mit Augen/Lippen-Retargeting

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results \
  --eye_retargeting 0.5 \
  --lip_retargeting 0.5
```

## Befehlsparameter

### Eingabeparameter

| Parameter | Beschreibung | Standardwert |
|-----------|--------------|--------------|
| `--source_image` | Eingabe-Porträtbild-Pfad | Erforderlich |
| `--driving_video` | Steuerungsvideo-Pfad | Optional |
| `--driven_audio` | Steuerungs-Audio-Pfad | Optional |
| `--result_dir` | Ausgabeverzeichnis | ./results |

### Verarbeitungsparameter

| Parameter | Beschreibung | Standardwert |
|-----------|--------------|--------------|
| `--stitching` | Stitching aktivieren | False |
| `--eye_retargeting` | Augen-Retargeting (0-1) | 0 |
| `--lip_retargeting` | Lippen-Retargeting (0-1) | 0 |
| `--face_parser` | Gesichtsparsung aktivieren | True |

### Leistungsparameter

| Parameter | Beschreibung | Standardwert |
|-----------|--------------|--------------|
| `--batch_size` | Batchgröße | 1 |
| `--fps` | Ausgabevideo-Bildrate | 30 |

## Verwendungsbeispiele

### Beispiel 1: Grundlegende video-gesteuerte Animation

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/basic
```

### Beispiel 2: Mit Stitching

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/stitching \
  --stitching
```

### Beispiel 3: Augensteuerung

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/eyes \
  --eye_retargeting 0.8
```

### Beispiel 4: Lippen-Synchronisation

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/lips \
  --lip_retargeting 0.7
```

### Beispiel 5: Volle Kontrolle

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/full \
  --stitching \
  --eye_retargeting 0.5 \
  --lip_retargeting 0.5
```

## Python API

### Grundlegende Verwendung

```python
from liveportrait import LivePortrait

# Initialisieren
lp = LivePortrait()

# Porträt animieren
result = lp.animate(
    source_image="image.jpg",
    driving_video="video.mp4",
    stitching=True,
    eye_retargeting=0.5,
    lip_retargeting=0.5
)

print(f"Video gespeichert unter: {result}")
```

### Erweiterte Verwendung

```python
from liveportrait import LivePortrait
import torch

# Mit benutzerdefinierten Einstellungen initialisieren
lp = LivePortrait(
    checkpoint_path="pretrained_models/liveportrait.pth",
    device="cuda" if torch.cuda.is_available() else "cpu"
)

# Mit voller Kontrolle generieren
result = lp.animate(
    source_image="image.jpg",
    driving_video="video.mp4",
    stitching=True,
    eye_retargeting=0.8,
    lip_retargeting=0.8,
    output_fps=30,
    output_resolution=(512, 512)
)
```

### Stapelverarbeitung

```python
from liveportrait import LivePortrait
import os

lp = LivePortrait()

# Mehrere Bilder verarbeiten
source_dir = "source_images/"
driving_video = "driving.mp4"

for image_file in os.listdir(source_dir):
    if image_file.endswith(('.jpg', '.png')):
        result = lp.animate(
            source_image=os.path.join(source_dir, image_file),
            driving_video=driving_video,
            stitching=True
        )
```

## Webinterface

### Webdemo ausführen

```bash
python app.py
```

Dann http://localhost:7860 im Browser öffnen

### Webinterface-Funktionen

1. **Quellbild hochladen** - Porträtbild hochladen
2. **Steuerungsvideo hochladen** - Steuerungsvideo auswählen
3. **Stitching-Schalter** - Stitching aktivieren/deaktivieren
4. **Augensteuerung** - Intensität der Augenbewegung anpassen
5. **Lippensteuerung** - Intensität der Lippensynchronisation anpassen
6. **Generieren** - Animation erstellen
7. **Herunterladen** - Ergebnis speichern

## Funktionen

### 1. Stitching

Das Stitching-Modul verbindet den generierten Kopf nahtlos mit dem Körper:

```bash
--stitching
```

- Glatter Übergang zwischen Kopf und Körper
- Funktioniert mit verschiedenen Bildstilen (realistisch, Ölgemälde, Skulptur, 3D)

### 2. Augen-Retargeting

Steuert die Augenöffnung mit einem Skalarwert (0-1):

```bash
--eye_retargeting 0.5
```

- 0: Geschlossene Augen
- 1: Vollständig offene Augen
- 0.5: Natürlich

### 3. Lippen-Retargeting

Steuert die Intensität der Lippenbewegung:

```bash
--lip_retargeting 0.5
```

- 0: Minimale Bewegung
- 1: Maximale Bewegung
- 0.5: Natürlich

## Eingabeanforderungen

### Quellbild

- Format: JPG, PNG
- Auflösung: 512x512 oder höher empfohlen
- Gesicht: Frontale Aufnahme, klar
- Hintergrund: Beliebig

### Steuerungsvideo

- Format: MP4, AVI
- Dauer: 1-60 Sekunden
- Auflösung: Beliebig
- Gesicht: Klare Gesichtsausdrücke

## Ausgabe

### Videoformat

- Format: MP4
- Codec: H.264
- Auflösung: 512x512
- Bildrate: 30

### Ausgabeverzeichnis

```
results/
├── output.mp4          # Generiertes Video
└── (temporäre Dateien)
```

## Fehlerbehebung

### Schlechte Animationsqualität

**Lösungen:**
- Hochwertigeres Quellbild verwenden
- Sicherstellen, dass Steuerungsvideo ein klares Gesicht hat
- Retargeting-Parameter anpassen

### Gesicht nicht erkannt

**Lösungen:**
- Klares Porträtbild verwenden
- Sicherstellen, dass das Gesicht sichtbar ist
- Bildformat überprüfen

### Langsame Verarbeitung

**Lösungen:**
- Ausgabeauflösung reduzieren
- Stitching deaktivieren, wenn nicht benötigt
- GPU-Beschleunigung verwenden

### GPU-Speicher voll

**Lösungen:**
- Batchgröße auf 1 reduzieren
- Kleinere Bildgröße verwenden
- Andere GPU-Anwendungen schließen

## Leistungstipps

### Schnellere Verarbeitung

1. Stitching deaktivieren, wenn nicht benötigt
2. Niedrigere Ausgabeauflösung verwenden
3. fps reduzieren

### Bessere Qualität

1. Stitching aktivieren
2. Hochwertiges Quellbild verwenden
3. Retargeting-Parameter anpassen

## Verwandte Links

- [GitHub](https://github.com/KwaiVGI/LivePortrait)
- [Paper](https://arxiv.org/abs/2407.03168)
- [Demo](https://liveportrait.github.io)
