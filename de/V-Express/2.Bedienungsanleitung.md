# V-Express Benutzerhandbuch

V-Express erzeugt Sprechkopfvideos unter der Steuerung eines Referenzbildes, Audios und V-Kps-Sequenzen.

## Schnellstart

### Grundbefehl

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/aud.mp3" \
  --kps_path "./test_samples/short_case/AOC/kps.pth" \
  --output_path "./output/result.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25
```

## Befehlsparameter

### Eingabeparameter

| Parameter | Beschreibung | Erforderlich |
|-----------|--------------|--------------|
| `--reference_image_path` | Pfad zum Referenzporträtbild | Ja |
| `--audio_path` | Pfad zur Eingabe-Audiodatei (MP3/WAV) | Ja |
| `--kps_path` | Pfad zur V-Kps-Sequenzdatei | Nein |
| `--output_path` | Pfad zum Ausgabevideo | Ja |

### Retargeting-Strategien

| Strategie | Beschreibung |
|-----------|--------------|
| `no_retarget` | Bild und Video derselben Person (beste Ergebnisse) |
| `fix_face` | Beliebiges Bild und Audio (nur Lippensynchronisation) |
| `offset_retarget` | Bild einer anderen Person mit leichter Gesichtsbewegung |
| `naive_retarget` | Bild einer anderen Person mit vollständigem Retargeting |

### Verarbeitungsparameter

| Parameter | Beschreibung | Standard |
|-----------|--------------|----------|
| `--retarget_strategy` | Gesichts-Retargeting-Strategie | no_retarget |
| `--num_inference_steps` | Anzahl der Inferenzschritte | 25 |
| `--reference_attention_weight` | Referenzbildgewicht (0.9-1.0) | 1.0 |
| `--audio_attention_weight` | Audiogewicht (1.0-3.0) | 1.0 |
| `--save_gpu_memory` | Speichersparmodus aktivieren | False |

### Empfohlene Parameterbereiche

- `reference_attention_weight`: 0.9-1.0
- `audio_attention_weight`: 1.0-3.0

## Verwendungsbeispiele

### Szenario 1: Gleiche Person (Beste Qualität)

Wenn Sie ein Bild von Person A und ein Sprechvideo von Person A haben:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/aud.mp3" \
  --kps_path "./test_samples/short_case/AOC/kps.pth" \
  --output_path "./output/talk_AOC_no_retarget.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25
```

### Szenario 2: Beliebiges Audio (Nur Lippensynchronisation)

Wenn Sie nur ein Bild und ein beliebiges Sprechaudio haben:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/tys/ref.jpg" \
  --audio_path "./test_samples/short_case/tys/aud.mp3" \
  --output_path "./output/talk_tys_fix_face.mp4" \
  --retarget_strategy "fix_face" \
  --num_inference_steps 25
```

### Szenario 3: Andere Person mit Gesichtsbewegung

Wenn Sie ein Bild von Person A und ein Sprechvideo von Person B haben:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/tys/ref.jpg" \
  --audio_path "./test_samples/short_case/tys/aud.mp3" \
  --kps_path "./test_samples/short_case/tys/kps.pth" \
  --output_path "./output/talk_tys_offset_retarget.mp4" \
  --retarget_strategy "offset_retarget" \
  --num_inference_steps 25
```

### Szenario 4: Benutzerdefinierte Aufmerksamkeitsgewichte

Gewichte für verschiedene Effekte anpassen:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/10/ref.jpg" \
  --audio_path "./test_samples/short_case/10/aud.mp3" \
  --output_path "./output/talk_10_weighted.mp4" \
  --retarget_strategy "fix_face" \
  --reference_attention_weight 0.95 \
  --audio_attention_weight 3.0
```

### Szenario 5: Langes Audio (Speicheroptimiert)

Für längere Audiodateien (30+ Sekunden):

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/long_audio.mp3" \
  --kps_path "./test_samples/short_case/AOC/AOC_raw_kps.pth" \
  --output_path "./output/long_video.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25 \
  --reference_attention_weight 1.0 \
  --audio_attention_weight 1.0 \
  --save_gpu_memory
```

## V-Kps-Sequenz extrahieren

Wenn Sie ein Zielvideo haben, extrahieren Sie die V-Kps-Sequenz:

```bash
python scripts/extract_kps_sequence_and_audio.py \
  --video_path "./test_samples/short_case/AOC/gt.mp4" \
  --kps_sequence_save_path "./test_samples/short_case/AOC/kps.pth" \
  --audio_save_path "./test_samples/short_case/AOC/aud.mp3"
```

## Eingabeanforderungen

### Referenzbild

- Format: JPG, PNG
- Auflösung: 512x512 oder höher (Quadrat empfohlen)
- Gesicht: Frontale Aufnahme, klar, keine Verdeckung
- Hintergrund: Einfach bevorzugt

### Audio

- Format: MP3, WAV
- Dauer: 1-60 Sekunden (länger mit --save_gpu_memory)
- Abtastrate: 16000-48000 Hz
- Sprache: Klar, minimales Rauschen

### V-Kps-Sequenz

- Format: PyTorch (.pth)
- Aus Zielvideo mit bereitgestelltem Skript generiert

## Ausgabe

### Videoformat

- Format: MP4
- Codec: H.264
- Auflösung: Wie Eingabe oder Standard 512x512
- Bildrate: 24-30

## Fehlerbehebung

### Schlechte Videoqualität

**Lösungen:**
- Verwenden Sie ein Referenzbild höherer Qualität (512x512+)
- Erhöhen Sie die Inferenzschritte (25-30)
- Passen Sie die Aufmerksamkeitsgewichte an

### Lippensynchronisationsprobleme

**Lösungen:**
- Erhöhen Sie `audio_attention_weight` (1.5-3.0)
- Verwenden Sie Audio höherer Qualität
- Stellen Sie sicher, dass das Audio klare Sprache enthält

### Gesichtsverformung

**Lösungen:**
- Verwenden Sie ähnliche Pose im Zielvideo
- Versuchen Sie eine andere Retargeting-Strategie
- Verwenden Sie no_retarget für dieselbe Person

### GPU-Speicher voll

**Lösungen:**
- Aktivieren Sie `--save_gpu_memory`
- Reduzieren Sie Inferenzschritte
- Verwenden Sie kürzeres Audio

### Verarbeitung zu langsam

**Lösungen:**
- Reduzieren Sie Inferenzschritte (15-20)
- Verwenden Sie ein kleineres Modell
- Deaktivieren Sie ungenutzte Funktionen

## Best Practices

1. **Videos derselben Person**: Verwenden Sie die `no_retarget`-Strategie für beste Ergebnisse
2. **Andere Person**: Wählen Sie ein Zielvideo mit ähnlicher Pose zum Referenzgesicht
3. **Bildqualität**: Verwenden Sie klare quadratische Gesichtsbilder von 512x512
4. **Audioqualität**: Verwenden Sie Audio mit klarer Sprache
5. **Gewichtsanpassung**: Passen Sie Aufmerksamkeitsgewichte für verschiedene Effekte an

## Verwandte Links

- [GitHub](https://github.com/tencent-ailab/V-Express)
- [HuggingFace](https://huggingface.co/tk93/V-Express)
- [Paper](https://arxiv.org/abs/2406.02511)
- [Projektseite](https://tenvence.github.io/p/v-express/)
