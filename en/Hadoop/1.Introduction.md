# Hadoop Introduction

> Apache Hadoop is an open-source framework for distributed storage and processing of large data sets

---

## Overview

Apache Hadoop is an open-source software framework used for distributed storage and processing of large data sets. It enables clustering multiple computers to analyze massive datasets in parallel, making it ideal for big data processing applications.

---

## Key Features

- **HDFS (Hadoop Distributed File System)**: Distributed file system that stores data across multiple machines
- **MapReduce**: Programming model for processing large datasets in parallel
- **YARN (Yet Another Resource Negotiator)**: Resource management layer for job scheduling
- **Scalability**: Scale from single servers to thousands of nodes
- **Fault Tolerance**: Automatic failure handling with data replication
- **Cost-effective**: Runs on commodity hardware
- **Ecosystem**: Rich set of tools including Hive, Pig, Spark, HBase

---

## Components

| Component | Description |
|-----------|-------------|
| HDFS | Distributed storage system |
| MapReduce | Data processing engine |
| YARN | Resource management |
| Hadoop Common | Shared utilities and libraries |

---

## Use Cases

- Big data analytics
- Log processing
- Data warehousing
- Machine learning
- ETL operations
- Search indexing

---

## Version

| Version | Release Date | Status |
|---------|--------------|--------|
| Hadoop 3.3 | 2021 | Current |
| Hadoop 3.2 | 2019 | Stable |
| Hadoop 3.1 | 2018 | Legacy |

---

## Resources

- Official Website: https://hadoop.apache.org/
- Documentation: https://hadoop.apache.org/docs/
- Releases: https://hadoop.apache.org/releases.html
