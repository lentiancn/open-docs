# V-Express Installationsanleitung

V-Express ist ein von Tencent AI Lab entwickeltes Verfahren zur Generierung von Porträtvideos. Es erzeugt Sprechkopfvideos unter der Steuerung eines Referenzbildes, Audios und V-Kps-Sequenzen.

## Versionsübersicht

| Version | Status | Beschreibung |
|---------|--------|--------------|
| V-Express 1.x | Aktuell | Hauptversion |

## Systemanforderungen

### Hardwareanforderungen

| Komponente | Minimum | Empfohlen |
|------------|---------|-----------|
| GPU | NVIDIA 16GB VRAM | NVIDIA 24GB+ VRAM |
| RAM | 16GB | 32GB+ |
| Speicher | 50GB | 100GB+ |
| CUDA | 11.8+ | 12.1+ |

### Softwareanforderungen

| Software | Version | Hinweise |
|----------|---------|----------|
| Python | 3.8 - 3.10 | Empfohlen 3.9 |
| CUDA | 11.8+ | GPU-Beschleunigung erforderlich |
| cuDNN | 8.5+ | Erforderlich für CUDA |
| ffmpeg | Neueste | Videobearbeitung erforderlich |

## Linux/Ubuntu Installation

### Schritt 1: Systemabhängigkeiten installieren

```bash
# System aktualisieren
sudo apt update && sudo apt upgrade -y

# Python und Entwicklungstools installieren
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Systembibliotheken installieren
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# ffmpeg installieren
sudo apt install ffmpeg

# git-lfs installieren
sudo apt install git-lfs
```

### Schritt 2: Projekt klonen

```bash
git clone https://github.com/tencent-ailab/V-Express.git
cd V-Express
```

### Schritt 3: Virtuelle Umgebung erstellen

```bash
python3.9 -m venv venv
source venv/bin/activate

# Python-Version überprüfen
python --version
```

### Schritt 4: PyTorch installieren

```bash
# CUDA 11.8 Version
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Installation überprüfen
python -c "import torch; print(torch.cuda.is_available())"
```

### Schritt 5: Abhängigkeiten installieren

```bash
pip install -r requirements.txt
```

### Schritt 6: Modelle herunterladen

```bash
# git-lfs installieren
git lfs install

# Modelle von HuggingFace klonen
git clone https://huggingface.co/tk93/V-Express

# Modelle an den richtigen Speicherort verschieben
mv V-Express/model_ckpts model_ckpts
mv V-Express/*.bin model_ckpts/v-express
```

Alternativ Modelle einzeln herunterladen:

```bash
# Modelle-Verzeichnis erstellen
mkdir -p model_ckpts

# Erforderliche Modelle herunterladen:
# - stabilityai/sd-vae-ft-mse
# - run wayml/stable-diffusion-v1-5 (nur unet Konfiguration)
# - facebook/wav2vec2-base-960h
# - insightface/buffalo_l
```

## Windows Installation

### Schritt 1: Python installieren

1. Python 3.9 von python.org herunterladen
2. "Add Python to PATH" während der Installation aktivieren
3. Überprüfen: `python --version`

### Schritt 2: CUDA installieren

1. CUDA 11.8 von der NVIDIA-Webseite herunterladen
2. Mit Standardeinstellungen installieren
3. cuDNN 8.9 herunterladen und installieren

### Schritt 3: Klonen und Einrichten

```powershell
git clone https://github.com/tencent-ailab/V-Express.git
cd V-Express

python -m venv venv
venv\Scripts\activate
```

### Schritt 4: Abhängigkeiten installieren

```powershell
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Schritt 5: Modelle herunterladen

Modelle von HuggingFace herunterladen und in das Verzeichnis `model_ckpts/` legen.

## macOS Installation

### Schritt 1: Abhängigkeiten installieren

```bash
# Homebrew installieren (falls nicht installiert)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Python und ffmpeg installieren
brew install python@3.9 ffmpeg git git-lfs
```

### Schritt 2: Einrichten

```bash
git clone https://github.com/tencent-ailab/V-Express.git
cd V-Express

python3.9 -m venv venv
source venv/bin/activate

# PyTorch installieren (nur CPU auf macOS)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Hinweis: macOS unterstützt nur den CPU-Modus, GPU-Beschleunigung ist nicht möglich.

## Installation überprüfen

```bash
# Grundfunktionalität testen
python inference.py --help
```

## Häufige Probleme

### CUDA Speicher voll

**Lösungen:**
- Inferenzschritte reduzieren: `--num_inference_steps 15`
- Speicher sparen aktivieren: `--save_gpu_memory`
- Niedrigere Auflösung verwenden

### Fehlende Bibliotheken (Windows)

**Lösungen:**
- Visual C++ Redistributable 2015-2022 installieren
- CUDA zum System-PATH hinzufügen

### Modell-Download fehlgeschlagen

**Lösungen:**
- VPN oder Proxy verwenden
- Manuell von HuggingFace herunterladen
- Netzwerkverbindung überprüfen

### ffmpeg nicht gefunden

**Lösungen:**
- Linux: `sudo apt install ffmpeg`
- Windows: ffmpeg zum PATH hinzufügen
- macOS: `brew install ffmpeg`

## Wichtige Hinweise

1. **Gesichts-Retargeting**: Wenn das Zielvideo nicht dieselbe Person wie das Referenzbild ist, ist Gesichts-Retargeting wichtig. Wählen Sie ein Zielvideo mit ähnlicher Pose wie das Referenzgesicht für bessere Ergebnisse.

2. **Sprachunterstützung**: Das Modell funktioniert besser auf Englisch; andere Sprachen wurden nicht detailliert getestet.

3. **Bildqualität**: Verwenden Sie klare quadratische Gesichtsbilder mit einer Auflösung von mindestens 512x512.

## Verwandte Links

- [GitHub-Repository](https://github.com/tencent-ailab/V-Express)
- [HuggingFace Modelle](https://huggingface.co/tk93/V-Express)
- [Paper](https://arxiv.org/abs/2406.02511)
- [Projektseite](https://tenvence.github.io/p/v-express/)
