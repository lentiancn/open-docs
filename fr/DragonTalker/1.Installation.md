# Guide d'installation DragonTalker

DragonTalker est un projet d'IA permettant de générer des vidéos réalistes de tête parlante à partir d'une seule image et d'un fichier audio, similaire à SadTalker. Il utilise l'apprentissage profond pour animer des images statiques avec des mouvements faciaux pilotés par l'audio.

## Vue d'ensemble de la version

| Version | Statut | Description |
|---------|--------|-------------|
| DragonTalker 1.x | Actuelle | Version principale |

**Note :** DragonTalker est une technologie émergente. Pour des solutions plus matures,可以考虑 SadTalker ou Wav2Lip.

## Configuration système

### Exigences matérielles

| Composant | Minimum | Recommandé |
|-----------|---------|------------|
| GPU | NVIDIA 6GB VRAM | NVIDIA 16GB VRAM |
| RAM | 8GB | 32GB |
| Stockage | 20GB | 50GB |
| CUDA | 11.7+ | 11.8+ |

### Exigences logicielles

| Logiciel | Version | Notes |
|----------|---------|-------|
| Python | 3.8 - 3.10 | 3.9 recommandé |
| CUDA | 11.7+ | Accélération GPU requise |
| cuDNN | 8.5+ | Requis pour CUDA |
| ffmpeg | Dernière version | Traitement vidéo requis |

## Installation Linux/Ubuntu

### Étape 1 : Installer les dépendances système

```bash
# Mettre à jour le système
sudo apt update && sudo apt upgrade -y

# Installer Python et les outils de développement
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Installer les bibliothèques système
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# Installer ffmpeg
sudo apt install ffmpeg
```

### Étape 2 : Installer CUDA (si nécessaire)

```bash
# Télécharger et installer CUDA 11.8
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

### Étape 3 : Cloner le projet

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker
```

### Étape 4 : Créer un environnement virtuel

```bash
python3.9 -m venv venv
source venv/bin/activate

# Vérifier la version de Python
python --version
```

### Étape 5 : Installer PyTorch

```bash
# Version CUDA 11.8
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Vérifier l'installation
python -c "import torch; print(torch.cuda.is_available())"
```

### Étape 6 : Installer les dépendances

```bash
pip install -r requirements.txt

# Installer des dépendances supplémentaires
pip install numpy opencv-python librosa soundfile
```

### Étape 7 : Télécharger les modèles

```bash
# Créer le répertoire des modèles
mkdir -p checkpoints

# Télécharger les modèles (voir les instructions du projet)
# bash scripts/download_models.sh
```

## Installation Windows

### Étape 1 : Installer Python

1. Télécharger Python 3.9 depuis python.org
2. Cocher "Add Python to PATH" lors de l'installation
3. Vérifier : `python --version`

### Étape 2 : Installer CUDA

1. Télécharger CUDA 11.8 depuis le site NVIDIA
2. Installer avec les paramètres par défaut
3. Télécharger et installer cuDNN 8.9

### Étape 3 : Cloner et configurer

```powershell
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python -m venv venv
venv\Scripts\activate
```

### Étape 4 : Installer les dépendances

```powershell
# Installer PyTorch (avec support CUDA)
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Étape 5 : Télécharger les modèles

Téléchargez les modèles depuis la page des versions du projet et place-les dans le répertoire `checkpoints/`.

## Installation macOS

### Étape 1 : Installer les dépendances

```bash
# Installer Homebrew (si non installé)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Installer Python et ffmpeg
brew install python@3.9 ffmpeg git
```

### Étape 2 : Configurer

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python3.9 -m venv venv
source venv/bin/activate

# Installer PyTorch (macOS CPU uniquement)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Note : macOS ne supporte que le mode CPU, l'accélération GPU n'est pas disponible.

## Installation Docker

### Utiliser Docker

```bash
# Tirer l'image
docker pull your-registry/dragontalker:latest

# Exécuter (requiert GPU)
docker run --gpus all -v $(pwd):/workspace -p 8888:8888 your-registry/dragontalker:latest
```

### Utiliser Docker Compose

```yaml
version: '3.8'
services:
  dragontalker:
    image: your-registry/dragontalker:latest
    volumes:
      - ./workspace:/workspace
    ports:
      - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## Vérifier l'installation

```bash
# Tester les fonctionnalités de base
python inference.py --help
```

## Problèmes courants

### Mémoire CUDA insuffisante

**Solutions :**
- Réduire la taille du lot : `--batch_size 1`
- Utiliser une résolution plus basse : `--size 256`
- Activer le déchargement du modèle

### Bibliothèques manquantes (Windows)

**Solutions :**
- Installer Visual C++ Redistributable 2015-2022
- Ajouter CUDA au PATH système

### Échec du téléchargement du modèle

**Solutions :**
- Utiliser un VPN ou un proxy
- Télécharger manuellement depuis GitHub Releases
- Vérifier la connexion réseau

### ffmpeg non trouvé

**Solutions :**
- Linux : `sudo apt install ffmpeg`
- Windows : Ajouter ffmpeg au PATH
- macOS : `brew install ffmpeg`

## Liens connexes

- [Dépôt GitHub](https://github.com/your-repo/DragonTalker)
- [Démo HuggingFace](https://huggingface.co/spaces)
- [Téléchargements des modèles](https://github.com/your-repo/DragonTalker/releases)
