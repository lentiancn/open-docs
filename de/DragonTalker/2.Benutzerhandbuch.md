# DragonTalker Benutzerhandbuch

DragonTalker verwendet Deep Learning, um realistische Sprechkopfvideos aus einem einzelnen Bild und Audio-Eingabe zu generieren.

## Schnellstart

### Grundbefehl

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results
```

### Mit Verbesserung

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results \
  --preprocess full \
  --enhancer gfpgan
```

## Befehlsparameter

### Eingabeparameter

| Parameter | Beschreibung | Standard |
|-----------|--------------|----------|
| `--source_image` | Pfad zum Eingabebild | Erforderlich |
| `--driven_audio` | Eingabe-Audiodatei (WAV/MP3) | Erforderlich |
| `--result_dir` | Ausgabeverzeichnis | ./results |

### Verarbeitungsparameter

| Parameter | Beschreibung | Standard |
|-----------|--------------|----------|
| `--preprocess` | Bildvorverarbeitung: crop, resize, full | full |
| `--size` | Bildgröße: 256, 512 | 256 |
| `--pose_style` | Posestil 0-45 | 0 |
| `--expression_scale` | Ausdrucksintensität 0.5-1.5 | 1.0 |

### Verbesserungsparameter

| Parameter | Beschreibung | Standard |
|-----------|--------------|----------|
| `--enhancer` | Gesichtsverbesserer: gfpgan, RestoreFormer, CodeFormer | Keine |

### Leistungsparameter

| Parameter | Beschreibung | Standard |
|-----------|--------------|----------|
| `--batch_size` | Stapelgröße | 1 |
| `--fps` | Video-Bildrate | 25 |

## Verwendungsbeispiele

### Beispiel 1: Grundlegende Generierung

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/basic
```

### Beispiel 2: GFPGAN-Verbesserung

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/enhanced \
  --enhancer gfpgan
```

### Beispiel 3: Benutzerdefinierte Pose

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/pose5 \
  --pose_style 5
```

### Beispiel 4: Höhere Auflösung

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/hd \
  --size 512 \
  --enhancer gfpgan
```

## Python API

### Grundlegende Verwendung

```python
from inference import DragonTalker

# DragonTalker initialisieren
dragon = DragonTalker()

# Video generieren
video_path = dragon.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="full",
    enhancer="gfpgan"
)

print(f"Video gespeichert unter: {video_path}")
```

### Erweiterte Verwendung

```python
from inference import DragonTalker
import torch

# Mit benutzerdefinierten Einstellungen initialisieren
dragon = DragonTalker(
    checkpoint_path="checkpoints/DragonTalker.pth",
    config_path="config/DragonTalker.yaml",
    device="cuda" if torch.cuda.is_available() else "cpu"
)

# Video mit erweiterten Optionen generieren
video_path = dragon.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="full",
    pose_style=10,
    expression_scale=1.2,
    enhancer="gfpgan",
    batch_size=1,
    output_video="output.mp4"
)
```

### Stapelverarbeitung

```python
from inference import DragonTalker
import os

dragon = DragonTalker()

# Mehrere Bilder verarbeiten (gleiches Audio)
audio_file = "audio.wav"
image_dir = "images/"

for image_file in os.listdir(image_dir):
    if image_file.endswith(('.jpg', '.png')):
        output_path = f"results/{image_file}"
        dragon.generate(
            source_image=os.path.join(image_dir, image_file),
            driven_audio=audio_file,
            preprocess="full"
        )
```

## Web-Oberfläche

### Web-Demo ausführen

```bash
python app.py
```

Dann http://localhost:8888 im Browser öffnen

### Funktionen der Web-Oberfläche

1. **Bild-Upload** - Porträtbild per Drag & Drop
2. **Audio-Upload** - Audiodatei auswählen (WAV/MP3)
3. **Vorschau** - Quellbild und Audio anzeigen
4. **Parametereinstellung** - Pose, Ausdruck, Verbesserer anpassen
5. **Generieren** - Video mit einem Klick erstellen
6. **Herunterladen** - Generiertes Video speichern

## Gesichtsverbesserer

### Verfügbare Verbesserer

| Verbesserer | Qualität | Geschwindigkeit | VRAM |
|-------------|----------|-----------------|------|
| Keine | Basic | Schnell | Niedrig |
| gfpgan | Gut | Mittel | Mittel |
| RestoreFormer | Sehr gut | Langsam | Hoch |
| CodeFormer | Sehr gut | Langsam | Hoch |

### Empfehlungen

- **Niedriger VRAM**: Kein Verbesserer oder gfpgan
- **Ausgewogen**: gfpgan
- **Beste Qualität**: RestoreFormer oder CodeFormer

## Vorverarbeitungsmodi

| Modus | Beschreibung | Anwendungsfall |
|-------|--------------|----------------|
| crop | Gesicht zentriert beschneiden | Schnelle Verarbeitung |
| resize | Auf Zielgröße skalieren | Einfacher Hintergrund |
| full | Vollständige Verarbeitungspipeline | Beste Qualität |

## Eingabeanforderungen

### Bidanforderungen

- Format: JPG, PNG
- Auflösung: 512x512 oder höher empfohlen
- Gesicht: Frontaufnahme, keine Verdeckung
- Hintergrund: Einfach bevorzugt

### Audioanforderungen

- Format: WAV, MP3
- Dauer: 1-60 Sekunden
- Abtastrate: 16000-48000 Hz
- Sprache: Klar, minimales Rauschen

## Ausgabe

### Videoformat

- Format: MP4
- Codec: H.264
- Auflösung: 256x256 oder 512x512
- Bildrate: 25
- Bitrate: 2-5 Mbps

### Ausgabeverzeichnis

Ergebnisse werden im angegebenen Ausgabeverzeichnis gespeichert:
```
results/
├── video.mp4          # Generiertes Video
└── (temporäre Dateien)
```

## Fehlerbehebung

### Video zu dunkel/hell

**Ursache:** Beleuchtungsunterschied zwischen Training und Eingabe

**Lösungen:**
- expression_scale-Parameter anpassen (0.8-1.2)
- Bildquelle höherer Qualität verwenden
- Verschiedenen Verbesserer testen

### Lippensynchronisation stimmt nicht

**Ursache:** Audioqualität oder Ausrichtungsproblem

**Lösungen:**
- Hochwertiges Audio verwenden
- Sicherstellen, dass Audio klare Sprache enthält
- Audio-Video-Synchronisation überprüfen

### Gesicht verformt

**Ursache:** Niedrige Eingabequalität oder ungewöhnliche Eingabe

**Lösungen:**
- Bild mit höherer Auflösung verwenden (512)
- Verschiedenen Vorverarbeitungsmodus testen
- Gesichtsverbesserer verwenden
- Sicherstellen, dass Gesicht deutlich sichtbar ist

### Langsame Verarbeitung

**Lösungen:**
- `--preprocess crop` verwenden
- `--size 256` einstellen
- Verbesserer deaktivieren
- Batch-Größe reduzieren

### GPU-Speicher voll

**Lösungen:**
- batch_size auf 1 reduzieren
- Kleinere Bildgröße verwenden
- Andere GPU-Anwendungen schließen

## Leistungstipps

### Schnellere Verarbeitung

1. `--preprocess crop` verwenden
2. `--size 256` einstellen
3. Verbesserer deaktivieren

### Bessere Qualität

1. `--size 512` verwenden
2. `--enhancer gfpgan` aktivieren
3. `--preprocess full` verwenden

## Verwandte Links

- [GitHub](https://github.com/your-repo/DragonTalker)
- [HuggingFace](https://huggingface.co/spaces)
- [Modelle](https://github.com/your-repo/DragonTalker/releases)
