# FantasyTalking - ユーザーマニュアル

詳細な使用方法と例。

## 基本的な使い方

### 動画生成

```bash
python inference.py \
  --source_image face.jpg \
  --audio speech.wav \
  --output output.mp4
```

### パラメータ

| パラメータ | 省略 | 説明 | デフォルト |
|-----------|------|------|-----------|
| --source_image | -s | 入力画像パス | 必須 |
| --audio | -a | 入力音声ファイル | 必須 |
| --output | -o | 出力動画パス | output.mp4 |
| --face_enhancer | -f | 顔強調モデル | None |
| --max_frames | -m | 最大フレーム数 | 300 |
| --fps | -fps | 出力FPS | 25 |

### 完全な例

```bash
python inference.py \
  --source_image photos/person1.jpg \
  --audio audio/speech.wav \
  --output results/video1.mp4 \
  --face_enhancer realusf \
  --fps 30
```

## 上級用法

### Python API

```python
from fantasytalking import FantasyTalking

# モデルを初期化
ft = FantasyTalking(
    checkpoint_path="./models/checkpoint.pth",
    face_enhancer="realusf"
)

# 動画を生成
ft.generate(
    source_image="face.jpg",
    audio="speech.wav",
    output="output.mp4"
)
```

### バッチ処理

```python
import os
from fantasytalking import FantasyTalking

ft = FantasyTalking()

images_dir = "./images"
audio_dir = "./audio"
output_dir = "./output"

for image_file in os.listdir(images_dir):
    for audio_file in os.listdir(audio_dir):
        output_name = f"{image_file}_{audio_file}.mp4"
        ft.generate(
            source_image=os.path.join(images_dir, image_file),
            audio=os.path.join(audio_dir, audio_file),
            output=os.path.join(output_dir, output_name)
        )
```

### Web APIサービス

```bash
# APIサービスを開始
python api.py --port 8080
```

呼び出し例：

```bash
curl -X POST http://localhost:8080/generate \
  -F "image=@face.jpg" \
  -F "audio=@speech.wav" \
  -o output.mp4
```

## 入力要件

### 画像フォーマット

- **対応形式**：JPG、PNG、BMP
- **推奨解像度**：512x512以上
- **顔の要件**：
  - 正面の-clear写真が最も効果的
  - 顔は画像の50%以上を占めるべき
  - 良好な照明、自然な表情

### 音声フォーマット

- **対応形式**：WAV、MP3、FLAC
- **サンプルレート**：16000 Hzまたは44100 Hz
- **長さ**：1-60秒を推奨
- **言語**：多言語自動検出対応

## 出力設定

### 解像度

```bash
# 出力解像度を設定
python inference.py --source_image face.jpg --audio speech.wav --output output.mp4 --size 512
```

対応解像度：256、512、768、1024

### FPS

```bash
# フレームレートを設定
python inference.py --source_image face.jpg --audio speech.wav --output output.mp4 --fps 30
```

### 動画形式

対応出力形式：MP4 (H.264)、AVI、MOV

## パフォーマンス最適化

### GPUアクセラレーション

CUDAを使用するように確認：

```python
ft = FantasyTalking(device="cuda")
```

### バッチ処理

複数のファイルにはバッチ処理を使用：

```python
ft.batch_generate(image_list, audio_list, output_dir)
```

### 混合精度

FP16アクセラレーションを有効化：

```python
ft = FantasyTalking(precision="fp16")
```

## 一般的な問題

### 動画生成に失敗？

1. 入力画像に顔が含まれているか確認
2. 音声形式が正しいか確認
3. VRAMが十分にあるか確認

### 顔が変形？

1. より明確な入力画像を使用
2. 顔キーポイントのパラメータを調整

### 唇的不同期？

1. 音声が明確か確認
2. 同期パラメータを調整

## ベストプラクティス

1. **適切な画像を選択**：正面、高解像度、均一な照明
2. **明確な音声を準備**：ノイズなし、話速は中程度
3. **パラメータを適切に設定**：必要に応じて解像度とFPSを調整
4. **顔強調を使用**：出力品質が向上

## 次のステップ

- FAQ：./4.FAQ.mdを参照
