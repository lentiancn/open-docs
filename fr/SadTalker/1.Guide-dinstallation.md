# Guide d'installation SadTalker

SadTalker est un projet d'IA pour générer des vidéos réalistes de têtes parlantes à partir d'une seule image et d'une entrée audio.

## Configuration requise

### Exigences matérielles

| Composant | Minimum | Recommandé |
|-----------|---------|------------|
| GPU | NVIDIA 6GB VRAM | NVIDIA 16GB VRAM |
| RAM | 8GB | 32GB |
| Stockage | 20GB libre | 50GB libre |
| OS | Ubuntu 18.04+, Windows 10+, macOS 11+ | Ubuntu 20.04+ |

### Exigences logicielles

| Logiciel | Version | Notes |
|----------|---------|-------|
| Python | 3.8 - 3.10 | 3.9 recommandé |
| CUDA | 11.7+ | Pour accélération GPU |
| cuDNN | 8.5+ | Requis pour CUDA |
| ffmpeg | Dernière version | Pour traitement vidéo |

## Installation sur Linux/Ubuntu

### Étape 1 : Installer les dépendances système

```bash
# Mettre à jour le système
sudo apt update && sudo apt upgrade -y

# Installer Python et outils de développement
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Installer les bibliothèques système
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# Installer ffmpeg
sudo apt install ffmpeg

# Installer les pilotes NVIDIA (si non installés)
sudo apt install nvidia-driver-525
```

### Étape 2 : Installer CUDA (si nécessaire)

```bash
# Télécharger et installer CUDA 11.8
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

### Étape 3 : Cloner le dépôt

```bash
git clone https://github.com/OpenTalker/SadTalker.git
cd SadTalker
```

### Étape 4 : Créer un environnement virtuel

```bash
python3.9 -m venv venv
source venv/bin/activate

# Vérifier la version Python
python --version
```

### Étape 5 : Installer PyTorch

```bash
# Pour CUDA 11.8
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Vérifier l'installation
python -c "import torch; print(torch.cuda.is_available())"
```

### Étape 6 : Installer les dépendances

```bash
pip install -r requirements.txt

# Installer les dépendances supplémentaires
pip install numpy opencv-python librosa soundfile
```

### Étape 7 : Télécharger les modèles

```bash
# Créer le répertoire des modèles
mkdir -p checkpoints

# Télécharger les modèles (automatique)
bash scripts/download_models.sh

# Ou télécharger manuellement depuis les releases
# Placer les modèles dans le répertoire checkpoints/
```

## Installation sur Windows

### Étape 1 : Installer Python

1. Télécharger Python 3.9 depuis python.org
2. Lors de l'installation, cocher "Add Python to PATH"
3. Vérifier : `python --version`

### Étape 2 : Installer CUDA

1. Télécharger CUDA 11.8 depuis le site NVIDIA
2. Installer avec les paramètres par défaut
3. Télécharger et installer cuDNN 8.9

### Étape 3 : Cloner et configurer

```powershell
git clone https://github.com/OpenTalker/SadTalker.git
cd SadTalker

python -m venv venv
venv\Scripts\activate
```

### Étape 4 : Installer les dépendances

```powershell
# Installer PyTorch avec support CUDA
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Étape 5 : Télécharger les modèles

Télécharger les modèles depuis la page releases GitHub et les placer dans le dossier `checkpoints/`.

## Installation sur macOS

### Étape 1 : Installer les dépendances

```bash
# Installer Homebrew (si non installé)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Installer Python et ffmpeg
brew install python@3.9 ffmpeg git
```

### Étape 2 : Configurer

```bash
git clone https://github.com/OpenTalker/SadTalker.git
cd SadTalker

python3.9 -m venv venv
source venv/bin/activate

# Installer PyTorch (CPU uniquement pour macOS)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Note : macOS fonctionne en mode CPU uniquement. L'accélération GPU n'est pas disponible.

## Installation Docker

### Utiliser Docker

```bash
# Tirer l'image
docker pull ghcr.io/opentalker/sadtalker:latest

# Exécuter avec support GPU
docker run --gpus all -v $(pwd):/workspace -p 8888:8888 ghcr.io/opentalker/sadtalker:latest
```

### Utiliser Docker Compose

```yaml
version: '3.8'
services:
  sadtalker:
    image: ghcr.io/opentalker/sadtalker:latest
    volumes:
      - ./workspace:/workspace
    ports:
      - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## Vérifier l'installation

```bash
# Tester la fonctionnalité de base
python inference.py --help

# Devrait afficher toutes les options disponibles
```

## Problèmes courants

### Mémoire CUDA épuisée

**Solution :**
- Réduire la taille du batch : `--batch_size 1`
- Utiliser une résolution plus basse : `--size 256`
- Activer le déchargement des modèles
- Fermer les autres applications GPU

### Bibliothèques manquantes (Windows)

**Solution :**
- Installer Visual C++ Redistributable 2015-2022
- Ajouter CUDA au PATH système

### Échec du téléchargement des modèles

**Solution :**
- Utiliser un VPN ou un proxy
- Télécharger manuellement depuis les releases GitHub
- Vérifier la connexion réseau

### ffmpeg introuvable

**Solution :**
- Linux : `sudo apt install ffmpeg`
- Windows : Ajouter ffmpeg au PATH
- macOS : `brew install ffmpeg`

## Liens connexes

- [Dépôt GitHub](https://github.com/OpenTalker/SadTalker)
- [Démo HuggingFace](https://huggingface.co/spaces/fffilo/SadTalker)
- [Article](https://arxiv.org/abs/2303.17550)
- [Téléchargement des modèles](https://github.com/OpenTalker/SadTalker/releases)
