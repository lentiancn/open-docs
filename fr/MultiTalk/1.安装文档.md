# Guide d'installation de MultiTalk

MultiTalk est un outil de génération audio multi-locuteurs qui crée des contenus audio multi-voix naturels.

## Informations de version

| Version | Statut | Description |
|---------|--------|-------------|
| MultiTalk v1.0 | ✅ Actuelle | Version initiale |

## Configuration requise

### Matériel requis

| Exigence | Minimum | Recommandé |
|-------------|---------|-------------|
| GPU | NVIDIA 4GB VRAM | NVIDIA 8GB+ VRAM |
| RAM | 8GB | 16GB+ |
| Stockage | 5GB | 10GB+ SSD |

### Logiciels requis

| Logiciel | Version |
|----------|---------|
| Python | 3.8+ |
| CUDA | 11.0+ |

## Méthodes d'installation

### Méthode 1 : À partir du code source

#### 1. Cloner le dépôt

```bash
git clone https://github.com/MultiTalk/MultiTalk.git
cd MultiTalk
```

#### 2. Créer un environnement virtuel

```bash
python -m venv venv
source venv/bin/activate  # Linux/macOS
# ou
venv\Scripts\activate  # Windows
```

#### 3. Installer les dépendances

```bash
pip install -r requirements.txt
```

#### 4. Télécharger les modèles

```bash
bash scripts/download_models.sh
```

### Méthode 2 : Docker

```bash
docker pull multitalk/multitalk:latest
docker run --gpus all -v /path/to/data:/data multitalk/multitalk:latest
```

## Configuration

### Variables d'environnement

```bash
export CUDA_VISIBLE_DEVICES=0
export PYTHONPATH=/path/to/MultiTalk:$PYTHONPATH
```

### Chemins des modèles

Modifier `config.yaml`:

```yaml
model:
  checkpoint_path: "checkpoints/multitalk.pth"
```

## Démarrage rapide

### Générer de l'audio multi-locuteurs

```bash
python inference.py \
  --text "Bonjour, ceci est une démonstration multi-locuteurs." \
  --speakers speaker1,speaker2 \
  --output output.wav
```

### Paramètres

```bash
--text         # Texte d'entrée
--speakers     # IDs des locuteurs (séparés par des virgules)
--output       # Chemin du fichier de sortie
--speed        # Vitesse de parole (par défaut : 1.0)
```

## Problèmes courants

### GPU non disponible ?

```bash
nvidia-smi
python -c "import torch; print(torch.cuda.is_available())"
```

### Échec du téléchargement du modèle ?

Vérifiez votre connexion Internet ou téléchargez les modèles manuellement.

## Liens connexes

- [MultiTalk GitHub](https://github.com/MultiTalk/MultiTalk)
