# DragonTalker 安装指南

> 详细记录 DragonTalker 在各操作系统环境下的安装步骤
> 
> 更新日期：2026年2月

---

## 一、背景介绍

DragonTalker 是一款基于深度学习的说话头像生成工具，能够从单张人物图像和音频文件合成逼真的动态说话视频。该技术广泛应用于虚拟主播、数字人客服、AI教育等场景。

### 1.1 核心技术

DragonTalker 采用多阶段流水线架构：首先通过音频分析提取梅尔频谱特征；其次利用 3D 面部关键点检测技术获取面部运动参数；然后结合图像渲染技术生成连续的视频帧；最后通过面部增强网络提升画质。整个过程不需要大量训练数据，部署便捷。

### 1.2 主要特性

- 音频驱动动画：仅需提供目标人物的静态图像和音频文件即可生成同步的说话视频
- 3D 运动估计：基于面部landmark的3D重建技术，生成自然的头部姿态和表情变化
- 多姿势支持：内置45种以上预定义头部姿势模板，满足不同应用场景需求
- 面部增强：集成 GFPGAN、RestoreFormer、CodeFormer 等先进的面部修复技术
- Web 演示界面：提供友好的浏览器端操作入口，无需配置开发环境
- Python API：提供完整的编程接口，支持二次开发和批量处理

---

## 二、系统要求

### 2.1 硬件配置

| 组件 | 最低配置 | 推荐配置 |
|------|----------|----------|
| 显卡 | NVIDIA GTX 1060 (6GB显存) | NVIDIA RTX 3080 及以上 (16GB显存) |
| 内存 | 8GB | 32GB |
| 存储空间 | 20GB 可用空间 | 50GB SSD |
| 系统盘 | - | 建议使用SSD以提升加载速度 |

### 2.2 软件环境

| 软件 | 版本要求 | 说明 |
|------|----------|------|
| 操作系统 | Ubuntu 18.04/20.04/22.04, Windows 10/11, macOS 11+ | 建议使用64位系统 |
| Python | 3.8 - 3.10 | 更高版本可能存在兼容性问题 |
| CUDA | 11.7 或更高 | GPU推理必需 |
| cuDNN | 与CUDA版本匹配 | 深度学习加速库 |
| ffmpeg | 任意稳定版本 | 视频编解码必需 |

### 2.3 网络要求

项目模型文件较大，首次安装需要良好的网络环境连接海外下载节点。建议配置代理或使用国内镜像源。

---

## 三、安装步骤

### 3.1 Ubuntu/Linux 安装

#### 3.1.1 系统依赖安装

打开终端，依次执行以下命令安装系统依赖：

```bash
# 更新软件包列表
sudo apt-get update

# 安装基础构建工具
sudo apt-get install -y build-essential git wget curl

# 安装Python及相关工具
sudo apt-get install -y python3.8 python3-pip python3-venv

# 安装视频处理依赖
sudo apt-get install -y ffmpeg libsm6 libxext6 libxrender-dev libgl1-mesa-glx

# 安装GPU驱动相关（如已安装NVIDIA驱动可跳过）
# 此步骤仅适用于全新安装环境
wget https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64/cuda-keyring_1.0-1_all.deb
sudo dpkg -i cuda-keyring_1.0-1_all.deb
sudo apt-get update
sudo apt-get install -y cuda
```

#### 3.1.2 创建虚拟环境

为避免与系统其他Python项目产生冲突，建议使用虚拟环境：

```bash
# 进入项目目录
cd DragonTalker

# 创建虚拟环境
python3 -m venv venv

# 激活虚拟环境
source venv/bin/activate

# 确认激活成功
python --version
```

#### 3.1.3 安装Python依赖

```bash
# 升级pip版本
pip install --upgrade pip

# 安装PyTorch（选择与CUDA版本匹配的版本）
pip install torch==1.12.1+cu113 torchvision==0.13.1+cu113 -f https://download.pytorch.org/whl/cu113

# 安装项目依赖
pip install -r requirements.txt
```

如果遇到网络问题，可以使用国内镜像源：

```bash
# 使用清华镜像
pip install -i https://pypi.tuna.tsinghua.edu.cn/simple -r requirements.txt
```

#### 3.1.4 下载预训练模型

```bash
# 执行模型下载脚本
bash scripts/download_models.sh
```

该脚本会自动下载以下模型文件：

- 面部检测模型：face_detection
- 3D关键点模型：3d_keypoint_estimator  
- 表情迁移模型：face_reenactment
- 面部增强模型：gfpgan、restoreformer、codeformer

模型文件通常保存在 `checkpoints` 目录下，总大小约 500MB。

### 3.2 Windows 安装

#### 3.2.1 安装前置软件

1. **安装 Python**：从 Python 官网下载 3.8-3.10 版本，安装时勾选 "Add Python to PATH"

2. **安装 Git**：从 Git 官网下载并安装

3. **安装 CUDA**：根据显卡型号从 NVIDIA 官网下载对应版本的 CUDA Toolkit 11.7+

4. **安装 ffmpeg**：推荐使用 Chocolatey 包管理器：
```powershell
choco install ffmpeg
```

#### 3.2.2 克隆项目并配置

```powershell
# 克隆项目
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

# 创建虚拟环境
python -m venv venv

# 激活虚拟环境
venv\Scripts\activate

# 安装依赖
pip install --upgrade pip
pip install torch==1.12.1+cu113 --extra-index-url https://download.pytorch.org/whl/cu113
pip install -r requirements.txt
```

#### 3.2.3 下载模型文件

```powershell
# 在PowerShell中执行
.\scripts\download_models.ps1
```

### 3.3 macOS 安装

#### 3.3.1 安装 Homebrew 和依赖

```bash
# 安装 Homebrew（如未安装）
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# 安装必要软件
brew install ffmpeg python@3.10 git wget
```

#### 3.3.2 配置 Python 环境

```bash
# 克隆项目
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

# 创建虚拟环境
python3 -m venv venv
source venv/bin/activate

# 安装PyTorch（macOS版本使用CPU或MPS）
pip install torch torchvision

# 安装项目依赖
pip install -r requirements.txt
```

#### 3.3.3 下载模型

```bash
bash scripts/download_models.sh
```

---

## 四、验证安装

安装完成后，可以通过以下方式验证环境是否正确配置：

### 4.1 检查 Python 环境

```bash
# 激活虚拟环境
source venv/bin/activate  # Linux/macOS
# 或
venv\Scripts\activate     # Windows

# 检查关键包版本
python -c "import torch; print(f'PyTorch: {torch.__version__}')"
python -c "import cv2; print(f'OpenCV: {cv2.__version__}')"
python -c "import librosa; print(f'Librosa: {librosa.__version__}')"
```

### 4.2 运行示例

```bash
# 运行官方示例
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results \
  --preprocess full \
  --enhancer gfpgan
```

成功运行后，会在 `./results` 目录下生成名为 `result.mp4` 的视频文件。

### 4.3 常见问题排查

| 问题现象 | 可能原因 | 解决方案 |
|---------|----------|----------|
| CUDA out of memory | 显存不足 | 减小 batch_size 或使用更小的输入分辨率 |
| ImportError: No module named 'xxx' | 依赖未安装完整 | 重新执行 pip install -r requirements.txt |
| 视频生成速度极慢 | GPU未识别 | 确认CUDA正确安装，运行 nvidia-smi 检查 |
| 模型下载失败 | 网络问题 | 配置代理或使用国内镜像源 |

---

## 五、Docker 安装（推荐）

为简化环境配置，推荐使用 Docker 方式部署：

### 5.1 构建镜像

```bash
docker build -t dragon-talker:latest .
```

### 5.2 运行容器

```bash
# 映射本地目录用于输入输出
docker run --gpus all -v $(pwd)/examples:/app/examples \
  -v $(pwd)/results:/app/results \
  dragon-talker:latest \
  python inference.py \
    --source_image /app/examples/source_image.jpg \
    --driven_audio /app/examples/driven_audio.wav \
    --result_dir /app/results
```

---

## 六、配置说明

### 6.1 配置文件位置

项目根目录下的 `config` 文件夹包含各项参数配置：

- `dataset_config.yaml`：数据集路径配置
- `model_config.yaml`：模型参数配置
- `inference_config.yaml`：推理参数配置

### 6.2 常用参数调整

| 参数 | 说明 | 推荐值 |
|------|------|--------|
| --preprocess | 图像预处理方式 | full |
| --enhancer | 面部增强算法 | gfpgan |
| --outputfps | 输出视频帧率 | 25 |
| --faceid_weight | 身份保持权重 | 0.5 |

---

## 七、卸载步骤

如需卸载 DragonTalker：

```bash
# 退出虚拟环境
deactivate

# 删除虚拟环境目录
rm -rf venv

# 如使用Docker
docker rmi dragon-talker:latest
```

---

## 八、参考资源

- 官方GitHub仓库：https://github.com/your-repo/DragonTalker
- 项目论文：查看 `docs/paper.md`
- 社区讨论：https://github.com/your-repo/DragonTalker/discussions
- 问题反馈：https://github.com/your-repo/DragonTalker/issues
