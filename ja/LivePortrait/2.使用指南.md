# LivePortrait 使用ガイド

LivePortraitは、駆動ビデオのモーションを使用して静的なポートレートをアニメーション化する効率的なポートレートアニメーションフレームワークです。

## クイックスタート

### 基本的なコマンド

```bash
# ビデオ駆動アニメーション
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir ./results
```

### ステッチング付き

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir ./results \
  --stitching
```

## コマンドパラメータ

### 入力パラメータ

| パラメータ | 説明 | デフォルト |
|-----------|------|-----------|
| `--source_image` | 入力ポートレート画像パス | 必須 |
| `--driving_video` | 駆動ビデオパス | オプション |
| `--result_dir` | 出力ディレクトリ | ./results |

### 処理パラメータ

| パラメータ | 説明 | デフォルト |
|-----------|------|-----------|
| `--stitching` | ステッチングを有効化 | False |
| `--eye_retargeting` | アイリターゲティング (0-1) | 0 |
| `--lip_retargeting` | リップリターゲティング (0-1) | 0 |

## 使用例

### 例1：基本的なビデオ駆動アニメーション

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/basic
```

### 例2：ステッチング付き

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/stitching \
  --stitching
```

## 機能

### 1. ステッチング

ステッチングモジュールは、生成されたヘッドをボディとシームレスに接続します：

```bash
--stitching
```

### 2. アイリターゲティング

スカラー値で目の開きを制御 (0-1)：

```bash
--eye_retargeting 0.5
```

### 3. リップリターゲティング

リップ movement intensityを制御：

```bash
--lip_retargeting 0.5
```

## 入力要件

### ソース画像

- フォーマット：JPG、PNG
- 解像度：512x512以上推奨
-  лицо：正面、鮮明

### 駆動ビデオ

- フォーマット：MP4、AVI
-  duration：1-60秒

## 出力

- フォーマット：MP4 (H.264)
- 解像度：512x512
- フレームレート：30

## 関連リンク

- [GitHub](https://github.com/KwaiVGI/LivePortrait)
- [デモ](https://liveportrait.github.io)
