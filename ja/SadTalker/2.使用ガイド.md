# SadTalker  使用ガイド

SadTalkerは、深層学習を使用して単一の画像と音声入力からリアルなアバター動画を生成します。

## クイックスタート

### 基本的なコマンド

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results
```

### エンハンサー付きで動画を生成

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results \
  --preprocess full \
  --enhancer gfpgan
```

## コマンドラインパラメータ

### 入力パラメータ

| パラメータ | 説明 | デフォルト |
|------------|------|------------|
| `--source_image` | 入力ポートレート画像パス | 必須 |
| `--driven_audio` | 入力音声ファイルパス（WAV/MP3） | 必須 |
| `--result_dir` | 出力ディレクトリ | ./results |

### 処理パラメータ

| パラメータ | 説明 | デフォルト |
|------------|------|------------|
| `--preprocess` | 画像前処理：crop、resize、full | full |
| `--size` | 画像サイズ：256、512 | 256 |
| `--pose_style` | ポーズスタイル 0-45 | 0 |
| `--expression_scale` | 表情強度 0.5-1.5 | 1.0 |

### エンハンスパラメータ

| パラメータ | 説明 | デフォルト |
|------------|------|------------|
| `--enhancer` | 顔エンハンサー：gfpgan、RestoreFormer、CodeFormer | なし |
| `--enhancer_background` | 背景をエンハンス | False |

### パフォーマンスパラメータ

| パラメータ | 説明 | デフォルト |
|------------|------|------------|
| `--batch_size` | 処理バッチサイズ | 1 |
| `--fps` | 出力動画FPS | 25 |
| `--faceid` | 顔IDを保持 | False |

### その他のパラメータ

| パラメータ | 説明 | デフォルト |
|------------|------|------------|
| `--help` | すべてのオプションを表示 | - |

## 使用例

### 例1：基本的な生成

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/basic
```

### 例2：GFPGANエンハンス付き

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/enhanced \
  --enhancer gfpgan
```

### 例3：カスタムポーズスタイル

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/pose5 \
  --pose_style 5
```

### 例4：高解像度

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/hd \
  --size 512 \
  --enhancer gfpgan
```

## Python API

### 基本的な使用法

```python
from inference import SadTalker

# SadTalkerの初期化
sadtalker = SadTalker()

# 動画の生成
video_path = sadtalker.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="full",
    enhancer="gfpgan"
)

print(f"動画保存先: {video_path}")
```

### 高度な使用法

```python
from inference import SadTalker
import torch

# カスタム設定で初期化
sadtalker = SadTalker(
    checkpoint_path="checkpoints/SadTalker.pth",
    config_path="config/SadTalker.yaml",
    device="cuda" if torch.cuda.is_available() else "cpu"
)

# 高度なオプションで生成
video_path = sadtalker.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="full",
    pose_style=10,
    expression_scale=1.2,
    enhancer="gfpgan",
    batch_size=1,
    output_video="output.mp4"
)
```

### バッチ処理

```python
from inference import SadTalker
import os

sadtalker = SadTalker()

# 同じ音声で複数の画像を処理
audio_file = "audio.wav"
image_dir = "images/"

for image_file in os.listdir(image_dir):
    if image_file.endswith(('.jpg', '.png')):
        output_path = f"results/{image_file}"
        sadtalker.generate(
            source_image=os.path.join(image_dir, image_file),
            driven_audio=audio_file,
            preprocess="full"
        )
```

## Webインターフェース

### Webデモの実行

```bash
python app.py
```

次にブラウザでhttp://localhost:8888を開く

### Webインターフェース機能

1. **画像アップロード**：ドラッグ＆ドロップまたはポートレート画像を選択
2. **音声アップロード**：音声ファイルを選択（WAV/MP3）
3. **プレビュー**：ソース画像と音声をプレビュー
4. **パラメータ調整**：ポーズ、表情、エンハンサーを調整
5. **生成**：ワンクリックで動画生成
6. **ダウンロード**：生成した動画を保存

### Webインターフェースコントロール

| コントロール | 説明 |
|--------------|------|
| Source Image | ポートレート写真をアップロード |
| Driven Audio | -speech音声をアップロード |
| Preprocess | 前処理モードを選択 |
| Pose Style | ポーズアニメーションスタイルを選択 |
| Enhancer | 顔品質エンハンサーを選択 |
| Generate Button | 動画生成を開始 |

## 顔エンハンサー

### 利用可能なエンハンサー

| エンハンサー | 品質 | 速度 | VRAM |
|-------------|------|------|------|
| なし | 基本的 | 高速 | 低 |
| gfpgan | 良い | 中 | 中 |
| RestoreFormer | 非常に良い | 遅い | 高 |
| CodeFormer | 非常に良い | 遅い | 高 |

### 推奨

- **低VRAM**：エンハンサーなしまたはgfpgan
- **バランス**：gfpgan
- **最高品質**：RestoreFormerまたはCodeFormer

## 前処理モード

| モード | 説明 | ユースケース |
|--------|------|--------------|
| crop | 顔を中心にクロップ | 高速処理 |
| resize | ターゲットサイズにリサイズ | 単純な背景 |
| full | パイプライン全体 | 最佳の結果 |

## 入力要件

### 画像要件

- 形式：JPG、PNG
- サイズ：512x512以上を推奨
- 顔：正面向き、鮮明
- 背景：シンプルな方が良好

### 音声要件

- 形式：WAV、MP3
- 長さ：1-60秒
- サンプルレート：16000-48000 Hz
- Speech：最小限のノイズのある明確な音声

## 出力

### 動画形式

- 形式：MP4
- コーデック：H.264
- 解像度：256x256 または 512x512
- FPS：25
- ビットレート：2-5 Mbps

### 出力ディレクトリ

結果は指定された結果ディレクトリに保存されます：
```
results/
├── video.mp4          # 生成された動画
├── video_idx.mp4     # インデックス付き（複数の場合）
└── (一時ファイル)
```

## トラブルシューティング

### 動画が暗すぎる/明るすぎる

**原因：** トレーニングと入力の照明の不一致

**解決策：**
- expression_scaleパラメータを調整（0.8-1.2）
- より高品質なソース画像を使用
- 別のエンハンサーを試す

### 唇的不同期

**原因：** 音声品質または整列の問題

**解決策：**
- 高品質な音声を使用
- 音声に明確なSpeechがあることを確認
- 音声-動画同期を確認
- 動画の長さに合わせて音声をトリミング

### 顔の歪み

**原因：** 低品質または異常な入力

**解決策：**
- より高解像度の画像を使用（512）
- 別の前処理モードを試す
- 顔エンハンサーを使用
- 顔が明確に見えることを確認

### 処理が遅い

**解決策：**
- バッチサイズを削減
- 解像度を低くする（--size 256）
- エンハンサーを無効化
- より高速な前処理を使用（crop）

### GPUメモリ不足

**解決策：**
- batch_sizeを1に削減
- より小さい画像サイズを使用
- 他のGPUアプリケーションを閉じる
- CPUオフロードを有効化

## パフォーマンスのヒント

### より高速な処理

1. `--preprocess crop`を使用
2. `--size 256`を設定
3. エンハンサーを無効化
4. バッチサイズを削減

### より良い品質

1. `--size 512`を使用
2. `--enhancer gfpgan`を有効化
3. `--preprocess full`を使用
4. `--expression_scale`を調整

### VRAM節約

1. 一つずつ処理
2. より小さいモデルを使用
3. 不要な機能を無効化

## 統合例

### Python Flask API

```python
from flask import Flask, request, send_file
from inference import SadTalker
import tempfile

app = Flask(__name__)
sadtalker = SadTalker()

@app.route('/generate', methods=['POST'])
def generate():
    image = request.files['image']
    audio = request.files['audio']
    
    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as img:
        image.save(img.name)
    
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as aud:
        audio.save(aud.name)
    
    video_path = sadtalker.generate(
        source_image=img.name,
        driven_audio=aud.name,
        preprocess="full"
    )
    
    return send_file(video_path, mimetype='video/mp4')
```

## 関連リンク

- [GitHub](https://github.com/OpenTalker/SadTalker)
- [HuggingFace](https://huggingface.co/spaces/fffilo/SadTalker)
- [論文](https://arxiv.org/abs/2303.17550)
- [モデル](https://github.com/OpenTalker/SadTalker/releases)
