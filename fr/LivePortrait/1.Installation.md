# Guide d'installation de LivePortrait

LivePortrait est un framework efficace d'animation de portraits développé par Kwai VGI. Il anime les portraits statiques en utilisant le mouvement des vidéos sources, avec support du contrôle du stitching et du re-targeting.

## Vue d'ensemble des versions

| Version | Statut | Description |
|---------|--------|-------------|
| LivePortrait 1.x | Actuelle | Version principale |

## Configuration requise

### Exigences matérielles

| Composant | Minimum | Recommandé |
|-----------|---------|------------|
| GPU | NVIDIA 8GB VRAM | NVIDIA 16GB VRAM |
| RAM | 8GB | 16GB |
| Stockage | 30GB | 50GB |
| CUDA | 11.8+ | 12.1+ |

### Exigences logicielles

| Logiciel | Version | Notes |
|----------|---------|-------|
| Python | 3.8 - 3.11 | Recommandé 3.10 |
| CUDA | 11.8+ | Accélération GPU requise |
| cuDNN | 8.5+ | Requis pour CUDA |
| ffmpeg | Dernière | Traitement vidéo requis |

## Installation Linux/Ubuntu

### Étape 1 : Installer les dépendances système

```bash
# Mettre à jour le système
sudo apt update && sudo apt upgrade -y

# Installer Python et les outils de développement
sudo apt install python3.10 python3-pip python3-venv git wget curl

# Installer les bibliothèques système
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# Installer ffmpeg
sudo apt install ffmpeg
```

### Étape 2 : Installer CUDA

```bash
# Télécharger et installer CUDA 12.1
wget https://developer.download.nvidia.com/compute/cuda/12.1.0/local_installers/cuda_12.1.0_520.53_linux.run
sudo sh cuda_12.1.0_520.53_linux.run
```

### Étape 3 : Cloner le projet

```bash
git clone https://github.com/KwaiVGI/LivePortrait.git
cd LivePortrait
```

### Étape 4 : Créer un environnement virtuel

```bash
python3.10 -m venv venv
source venv/bin/activate

# Vérifier la version de Python
python --version
```

### Étape 5 : Installer PyTorch

```bash
# Version pour CUDA 12.1
pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu121

# Vérifier l'installation
python -c "import torch; print(torch.cuda.is_available())"
```

### Étape 6 : Installer les dépendances

```bash
# Installer les exigences de base
pip install -r requirements.txt

# Installer les dépendances supplémentaires
pip install numpy opencv-python librosa soundfile
```

### Étape 7 : Télécharger les modèles

```bash
# Créer le répertoire des modèles
mkdir -p pretrained_models

# Télécharger depuis la page des versions ou utiliser le script
bash scripts/download_weights.sh
```

## Installation Windows

### Étape 1 : Installer Python

1. Télécharger Python 3.10 depuis python.org
2. Cocher "Add Python to PATH" lors de l'installation
3. Vérifier : `python --version`

### Étape 2 : Installer CUDA

1. Télécharger CUDA 12.1 depuis le site NVIDIA
2. Installer avec les paramètres par défaut
3. Télécharger et installer cuDNN 8.9

### Étape 3 : Cloner et configurer

```powershell
git clone https://github.com/KwaiVGI/LivePortrait.git
cd LivePortrait

python -m venv venv
venv\Scripts\activate
```

### Étape 4 : Installer les dépendances

```powershell
# Installer PyTorch (avec support CUDA)
pip install torch==2.1.0 torchvision==0.16.0 --index-url https://download.pytorch.org/whl/cu121

pip install -r requirements.txt
```

### Étape 5 : Télécharger les modèles

Télécharger les modèles depuis GitHub releases et placer dans le répertoire `pretrained_models/`.

## Installation macOS

### Étape 1 : Installer les dépendances

```bash
# Installer Homebrew (si pas installé)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Installer Python et ffmpeg
brew install python@3.10 ffmpeg git
```

### Étape 2 : Configurer

```bash
git clone https://github.com/KwaiVGI/LivePortrait.git
cd LivePortrait

python3.10 -m venv venv
source venv/bin/activate

# Installer PyTorch (macOS CPU uniquement)
pip install torch==2.1.0 torchvision==0.16.0

pip install -r requirements.txt
```

Note : macOS supporte uniquement le mode CPU, l'accélération GPU n'est pas disponible.

## Installation Docker

### Utiliser Docker

```bash
# Télécharger l'image
docker pull liveportrait:latest

# Exécuter (nécessite GPU)
docker run --gpus all -v $(pwd):/workspace -p 7860:7860 liveportrait:latest
```

### Utiliser Docker Compose

```yaml
version: '3.8'
services:
  liveportrait:
    image: liveportrait:latest
    volumes:
      - ./workspace:/workspace
    ports:
      - "7860:7860"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## Vérifier l'installation

```bash
# Tester la fonctionnalité de base
python inference.py --help
```

## Problèmes courants

### Mémoire CUDA insuffisante

**Solutions :**
- Réduire la taille du batch : `--batch_size 1`
- Utiliser une résolution plus basse
- Activer le déchargement du modèle

### Bibliothèques manquantes (Windows)

**Solutions :**
- Installer Visual C++ Redistributable 2015-2022
- Ajouter CUDA au PATH système

### Échec du téléchargement du modèle

**Solutions :**
- Utiliser un VPN ou proxy
- Télécharger manuellement depuis GitHub releases
- Vérifier la connexion réseau

### ffmpeg non trouvé

**Solutions :**
- Linux : `sudo apt install ffmpeg`
- Windows : Ajouter ffmpeg au PATH
- macOS : `brew install ffmpeg`

## Liens connexes

- [Dépôt GitHub](https://github.com/KwaiVGI/LivePortrait)
- [Article](https://arxiv.org/abs/2407.03168)
- [Démo](https://liveportrait.github.io)
