# V-Express Руководство по использованию

V-Express создаёт видео говорящих голов под управлением референсного изображения, аудио и последовательностей V-Kps.

## Быстрый старт

### Основная команда

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/aud.mp3" \
  --kps_path "./test_samples/short_case/AOC/kps.pth" \
  --output_path "./output/result.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25
```

## Параметры команды

### Параметры ввода

| Параметр | Описание | Обязательно |
|----------|----------|-------------|
| `--reference_image_path` | Путь к референсному портретному изображению | Да |
| `--audio_path` | Путь к входному аудиофайлу (MP3/WAV) | Да |
| `--kps_path` | Путь к файлу последовательности V-Kps | Нет |
| `--output_path` | Путь к выходному видео | Да |

### Стратегии ретаргетинга

| Стратегия | Описание |
|-----------|----------|
| `no_retarget` | Изображение и видео одного человека (лучшие результаты) |
| `fix_face` | Любое изображение и аудио (только синхронизация губ) |
| `offset_retarget` | Изображение другого человека с небольшим движением лица |
| `naive_retarget` | Изображение другого человека с полным ретаргетингом |

### Параметры обработки

| Параметр | Описание | По умолчанию |
|----------|----------|--------------|
| `--retarget_strategy` | Стратегия ретаргетинга лица | no_retarget |
| `--num_inference_steps` | Количество шагов вывода | 25 |
| `--reference_attention_weight` | Вес референсного изображения (0.9-1.0) | 1.0 |
| `--audio_attention_weight` | Вес аудио (1.0-3.0) | 1.0 |
| `--save_gpu_memory` | Включить режим экономии памяти | False |

### Рекомендуемые диапазоны параметров

- `reference_attention_weight`: 0.9-1.0
- `audio_attention_weight`: 1.0-3.0

## Примеры использования

### Сценарий 1: Один человек (лучшее качество)

Когда у вас есть изображение человека A и говорящее видео человека A:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/aud.mp3" \
  --kps_path "./test_samples/short_case/AOC/kps.pth" \
  --output_path "./output/talk_AOC_no_retarget.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25
```

### Сценарий 2: Любое аудио (только синхронизация губ)

Когда у вас есть только изображение и любое говорящее аудио:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/tys/ref.jpg" \
  --audio_path "./test_samples/short_case/tys/aud.mp3" \
  --output_path "./output/talk_tys_fix_face.mp4" \
  --retarget_strategy "fix_face" \
  --num_inference_steps 25
```

### Сценарий 3: Разные люди с движением лица

Когда у вас есть изображение человека A и говорящее видео человека B:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/tys/ref.jpg" \
  --audio_path "./test_samples/short_case/tys/aud.mp3" \
  --kps_path "./test_samples/short_case/tys/kps.pth" \
  --output_path "./output/talk_tys_offset_retarget.mp4" \
  --retarget_strategy "offset_retarget" \
  --num_inference_steps 25
```

### Сценарий 4: Пользовательские веса внимания

Настройка весов для разных эффектов:

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/10/ref.jpg" \
  --audio_path "./test_samples/short_case/10/aud.mp3" \
  --output_path "./output/talk_10_weighted.mp4" \
  --retarget_strategy "fix_face" \
  --reference_attention_weight 0.95 \
  --audio_attention_weight 3.0
```

### Сценарий 5: Длинное аудио (оптимизация памяти)

Для более длинных аудиофайлов (30+ секунд):

```bash
python inference.py \
  --reference_image_path "./test_samples/short_case/AOC/ref.jpg" \
  --audio_path "./test_samples/short_case/AOC/long_audio.mp3" \
  --kps_path "./test_samples/short_case/AOC/AOC_raw_kps.pth" \
  --output_path "./output/long_video.mp4" \
  --retarget_strategy "no_retarget" \
  --num_inference_steps 25 \
  --reference_attention_weight 1.0 \
  --audio_attention_weight 1.0 \
  --save_gpu_memory
```

## Извлечение последовательности V-Kps

Если у вас есть целевое видео, извлеките последовательность V-Kps:

```bash
python scripts/extract_kps_sequence_and_audio.py \
  --video_path "./test_samples/short_case/AOC/gt.mp4" \
  --kps_sequence_save_path "./test_samples/short_case/AOC/kps.pth" \
  --audio_save_path "./test_samples/short_case/AOC/aud.mp3"
```

## Требования к вводу

### Референсное изображение

- Формат: JPG, PNG
- Разрешение: 512x512 или выше (квадратное рекомендуется)
- Лицо: Анфас, чёткое, без заслонений
- Фон: Простой предпочтительнее

### Аудио

- Формат: MP3, WAV
- Длительность: 1-60 секунд (дольше с --save_gpu_memory)
- Частота дискретизации: 16000-48000 Гц
- Речь: Чёткая, минимальный шум

### Последовательность V-Kps

- Формат: PyTorch (.pth)
- Генерируется из целевого видео с помощью предоставленного скрипта

## Вывод

### Формат видео

- Формат: MP4
- Кодек: H.264
- Разрешение: Как на входе или по умолчанию 512x512
- Частота кадров: 24-30

## Устранение проблем

### Низкое качество видео

**Решения:**
- Использовать референсное изображение более высокого качества (512x512+)
- Увеличить шаги вывода (25-30)
- Настроить веса внимания

### Проблемы с синхронизацией губ

**Решения:**
- Увеличить `audio_attention_weight` (1.5-3.0)
- Использовать аудио более высокого качества
- Убедиться, что аудио содержит чёткую речь

### Деформация лица

**Решения:**
- Использовать похожую позу в целевом видео
- Попробовать другую стратегию ретаргетинга
- Использовать no_retarget для одного человека

### Недостаточно памяти GPU

**Решения:**
- Включить `--save_gpu_memory`
- Уменьшить шаги вывода
- Использовать более короткое аудио

### Обработка слишком медленная

**Решения:**
- Уменьшить шаги вывода (15-20)
- Использовать меньшую модель
- Отключить неиспользуемые функции

## Рекомендации

1. **Видео одного человека**: Используйте стратегию `no_retarget` для лучших результатов
2. **Разные люди**: Выбирайте целевое видео с позой, похожей на референсное лицо
3. **Качество изображения**: Используйте чёткие квадратные изображения лица 512x512
4. **Качество аудио**: Используйте аудио с чёткой речью
5. **Настройка весов**: Настраивайте веса внимания для разных эффектов

## Ссылки

- [GitHub](https://github.com/tencent-ailab/V-Express)
- [HuggingFace](https://huggingface.co/tk93/V-Express)
- [Статья](https://arxiv.org/abs/2406.02511)
- [Страница проекта](https://tenvence.github.io/p/v-express/)
