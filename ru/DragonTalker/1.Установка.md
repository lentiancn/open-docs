# Руководство по установке DragonTalker

DragonTalker — это проект искусственного интеллекта для создания реалистичных видео с говорящей головой из одного изображения и аудио, аналогичный SadTalker. Он использует глубокое обучение для анимации статических изображений с помощью управляемых аудио движений лица.

## Версия

| Версия | Статус | Описание |
|--------|--------|----------|
| DragonTalker 1.x | Текущая | Основной выпуск |

**Примечание:** DragonTalker — это развивающаяся технология. Для более зрелых решений рассмотрите SadTalker или Wav2Lip.

## Системные требования

### Аппаратные требования

| Компонент | Минимум | Рекомендуется |
|-----------|---------|---------------|
| GPU | NVIDIA 6GB VRAM | NVIDIA 16GB VRAM |
| RAM | 8GB | 32GB |
| Накопитель | 20GB | 50GB |
| CUDA | 11.7+ | 11.8+ |

### Программные требования

| Программа | Версия | Примечания |
|-----------|--------|------------|
| Python | 3.8 - 3.10 | Рекомендуется 3.9 |
| CUDA | 11.7+ | Требуется ускорение GPU |
| cuDNN | 8.5+ | Требуется для CUDA |
| ffmpeg | Последняя версия | Требуется для обработки видео |

## Установка в Linux/Ubuntu

### Шаг 1: Установка системных зависимостей

```bash
# Обновление системы
sudo apt update && sudo apt upgrade -y

# Установка Python и инструментов разработки
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Установка системных библиотек
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# Установка ffmpeg
sudo apt install ffmpeg
```

### Шаг 2: Установка CUDA (при необходимости)

```bash
# Загрузка и установка CUDA 11.8
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

### Шаг 3: Клонирование проекта

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker
```

### Шаг 4: Создание виртуальной среды

```bash
python3.9 -m venv venv
source venv/bin/activate

# Проверка версии Python
python --version
```

### Шаг 5: Установка PyTorch

```bash
# Версия для CUDA 11.8
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Проверка установки
python -c "import torch; print(torch.cuda.is_available())"
```

### Шаг 6: Установка зависимостей

```bash
pip install -r requirements.txt

# Установка дополнительных зависимостей
pip install numpy opencv-python librosa soundfile
```

### Шаг 7: Загрузка моделей

```bash
# Создание директории для моделей
mkdir -p checkpoints

# Загрузка моделей (проверьте инструкции проекта)
# bash scripts/download_models.sh
```

## Установка в Windows

### Шаг 1: Установка Python

1. Загрузите Python 3.9 с python.org
2. Отметьте "Add Python to PATH" при установке
3. Проверьте: `python --version`

### Шаг 2: Установка CUDA

1. Загрузите CUDA 11.8 с сайта NVIDIA
2. Установите с настройками по умолчанию
3. Загрузите и установите cuDNN 8.9

### Шаг 3: Клонирование и настройка

```powershell
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python -m venv venv
venv\Scripts\activate
```

### Шаг 4: Установка зависимостей

```powershell
# Установка PyTorch (с поддержкой CUDA)
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Шаг 5: Загрузка моделей

Загрузите модели со страницы релизов проекта и поместите их в директорию `checkpoints/`.

## Установка в macOS

### Шаг 1: Установка зависимостей

```bash
# Установка Homebrew (если не установлен)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Установка Python и ffmpeg
brew install python@3.9 ffmpeg git
```

### Шаг 2: Настройка

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python3.9 -m venv venv
source venv/bin/activate

# Установка PyTorch (macOS только CPU)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Примечание: macOS поддерживает только режим CPU, использовать ускорение GPU невозможно.

## Установка через Docker

### Использование Docker

```bash
# Загрузка образа
docker pull your-registry/dragontalker:latest

# Запуск (требуется GPU)
docker run --gpus all -v $(pwd):/workspace -p 8888:8888 your-registry/dragontalker:latest
```

### Использование Docker Compose

```yaml
version: '3.8'
services:
  dragontalker:
    image: your-registry/dragontalker:latest
    volumes:
      - ./workspace:/workspace
    ports:
      - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## Проверка установки

```bash
# Тестирование базовой функциональности
python inference.py --help
```

## Распространённые проблемы

### Недостаточно памяти CUDA

**Решения:**
- Уменьшить размер партии: `--batch_size 1`
- Использовать меньшее разрешение: `--size 256`
- Включить выгрузку модели

### Отсутствуют библиотеки (Windows)

**Решения:**
- Установить Visual C++ Redistributable 2015-2022
- Добавить CUDA в системный PATH

### Ошибка загрузки модели

**Решения:**
- Использовать VPN или прокси
- Загрузить вручную с GitHub Releases
- Проверить сетевое подключение

### ffmpeg не найден

**Решения:**
- Linux: `sudo apt install ffmpeg`
- Windows: Добавить ffmpeg в PATH
- macOS: `brew install ffmpeg`

## Ссылки

- [GitHub репозиторий](https://github.com/your-repo/DragonTalker)
- [HuggingFace Demo](https://huggingface.co/spaces)
- [Загрузка моделей](https://github.com/your-repo/DragonTalker/releases)
