# DragonTalker Installation Guide

DragonTalker is an AI project for generating realistic talking head videos from a single image and audio input, similar to SadTalker. It uses deep learning to animate static images with audio-driven facial movements.

## Version Overview

| Version | Status | Description |
|---------|--------|-------------|
| DragonTalker 1.x | Current | Main release |

**Note:** DragonTalker is an emerging technology. For more mature solutions, consider SadTalker or Wav2Lip.

## System Requirements

### Hardware Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| GPU | NVIDIA 6GB VRAM | NVIDIA 16GB VRAM |
| RAM | 8GB | 32GB |
| Storage | 20GB | 50GB |
| CUDA | 11.7+ | 11.8+ |

### Software Requirements

| Software | Version | Notes |
|----------|---------|-------|
| Python | 3.8 - 3.10 | Recommend 3.9 |
| CUDA | 11.7+ | GPU acceleration required |
| cuDNN | 8.5+ | Required for CUDA |
| ffmpeg | Latest | Video processing required |

## Linux/Ubuntu Installation

### Step 1: Install System Dependencies

```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install Python and development tools
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Install system libraries
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# Install ffmpeg
sudo apt install ffmpeg
```

### Step 2: Install CUDA (if needed)

```bash
# Download and install CUDA 11.8
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

### Step 3: Clone Project

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker
```

### Step 4: Create Virtual Environment

```bash
python3.9 -m venv venv
source venv/bin/activate

# Verify Python version
python --version
```

### Step 5: Install PyTorch

```bash
# CUDA 11.8 version
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Verify installation
python -c "import torch; print(torch.cuda.is_available())"
```

### Step 6: Install Dependencies

```bash
pip install -r requirements.txt

# Install additional dependencies
pip install numpy opencv-python librosa soundfile
```

### Step 7: Download Models

```bash
# Create models directory
mkdir -p checkpoints

# Download models (check project for specific instructions)
# bash scripts/download_models.sh
```

## Windows Installation

### Step 1: Install Python

1. Download Python 3.9 from python.org
2. Check "Add Python to PATH" during installation
3. Verify: `python --version`

### Step 2: Install CUDA

1. Download CUDA 11.8 from NVIDIA website
2. Install with default settings
3. Download and install cuDNN 8.9

### Step 3: Clone and Setup

```powershell
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python -m venv venv
venv\Scripts\activate
```

### Step 4: Install Dependencies

```powershell
# Install PyTorch (with CUDA support)
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Step 5: Download Models

Download models from project releases and place in `checkpoints/` directory.

## macOS Installation

### Step 1: Install Dependencies

```bash
# Install Homebrew (if not installed)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install Python and ffmpeg
brew install python@3.9 ffmpeg git
```

### Step 2: Setup

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python3.9 -m venv venv
source venv/bin/activate

# Install PyTorch (macOS CPU only)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Note: macOS only supports CPU mode, cannot use GPU acceleration.

## Docker Installation

### Using Docker

```bash
# Pull image
docker pull your-registry/dragontalker:latest

# Run (requires GPU)
docker run --gpus all -v $(pwd):/workspace -p 8888:8888 your-registry/dragontalker:latest
```

### Using Docker Compose

```yaml
version: '3.8'
services:
  dragontalker:
    image: your-registry/dragontalker:latest
    volumes:
      - ./workspace:/workspace
    ports:
      - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## Verify Installation

```bash
# Test basic functionality
python inference.py --help
```

## Common Issues

### CUDA Out of Memory

**Solutions:**
- Reduce batch size: `--batch_size 1`
- Use lower resolution: `--size 256`
- Enable model offloading

### Missing Libraries (Windows)

**Solutions:**
- Install Visual C++ Redistributable 2015-2022
- Add CUDA to system PATH

### Model Download Failed

**Solutions:**
- Use VPN or proxy
- Download manually from GitHub releases
- Check network connection

### ffmpeg Not Found

**Solutions:**
- Linux: `sudo apt install ffmpeg`
- Windows: Add ffmpeg to PATH
- macOS: `brew install ffmpeg`

## Related Links

- [GitHub Repository](https://github.com/your-repo/DragonTalker)
- [HuggingFace Demo](https://huggingface.co/spaces)
- [Model Downloads](https://github.com/your-repo/DragonTalker/releases)
