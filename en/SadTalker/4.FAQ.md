# SadTalker Frequently Asked Questions

## General Questions

### What is SadTalker?
SadTalker is a deep learning project that generates realistic talking face videos from a single static image and audio input. It creates lip-synced facial animations using 3D facial motion coefficients.

### Is SadTalker free to use?
Yes, SadTalker is open-source and free for personal and research purposes. Check the LICENSE file for details.

### What are the system requirements?
- **GPU**: NVIDIA GPU with 8GB+ VRAM (recommended)
- **RAM**: 8GB minimum, 16GB recommended
- **Storage**: 20GB+ for models and outputs
- **OS**: Linux (Ubuntu 20.04+), Windows 10/11, macOS

## Installation Questions

### How do I install SadTalker?
```bash
# Clone the repository
git clone https://github.com/WinfredSadTalker/SadTalker.git
cd SadTalker

# Create conda environment
conda create -n sadtalker python=3.8
conda activate sadtalker

# Install dependencies
pip install -r requirements.txt

# Download pretrained models
bash scripts/download_models.sh
```

### Which Python version should I use?
SadTalker works best with Python 3.8 or 3.9. Python 3.10+ may have compatibility issues.

### Do I need a GPU?
A GPU is highly recommended for reasonable performance. CPU inference is possible but very slow.

## Usage Questions

### How do I generate a talking video?
```bash
python inference.py --source_image path/to/image.jpg --audio path/to/audio.wav
```

### What image formats are supported?
- JPG/JPEG
- PNG
- Most common image formats

### What audio formats are supported?
- WAV (recommended)
- MP3
- Other formats supported by FFmpeg

### How long does generation take?
Processing time depends on:
- Video length (typically 1-2 seconds per second of audio)
- GPU performance
- Model settings
- Resolution

## Troubleshooting

### The model fails to download
Manually download models from the official repository or use alternative sources mentioned in the documentation.

### Out of memory errors
- Reduce batch size
- Lower output resolution
- Use model swapping
- Close other GPU applications

### Poor quality results
- Use high-resolution input images
- Ensure clear audio without background noise
- Adjust enhancement parameters
- Try different preprocessing options

### Face detection fails
- Use images with clearly visible faces
- Ensure front-facing pose
- Avoid heavily occluded faces
- Check face detection model files

## Advanced Questions

### Can I use SadTalker commercially?
Check the license terms. Some components may have restrictions for commercial use.

### How does SadTalker work?
SadTalker uses:
1. Face detection to locate facial landmarks
2. Audio feature extraction using wav2vec or similar
3. 3D face model generation (3DMM)
4. Motion coefficient prediction from audio
5. Video rendering with face rendering network

### Can I train my own model?
Yes, you can fine-tune SadTalker on custom datasets. See the training documentation for details.

## Known Issues

- Some artifacts may appear in generated videos
- Limited support for non-front-facing poses
- May not work well with low-quality images
- Processing can be slow on older hardware

## Resources

- Official GitHub: https://github.com/WinfredSadTalker/SadTalker
- Paper: SadTalker paper on arXiv
- Community: Discussions on GitHub Issues
