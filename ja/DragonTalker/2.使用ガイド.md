# DragonTalker 使用ガイド

DragonTalkerは、深度学習を使用して単一の画像と音声入力からリアルなアバター動画を生成します。

## クイックスタート

### 基本的なコマンド

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results
```

### 画質向上機能付き

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results \
  --preprocess full \
  --enhancer gfpgan
```

## コマンドパラメータ

### 入力パラメータ

| パラメータ | 説明 | デフォルト |
|------------|------|------------|
| `--source_image` | 入力ポートレート画像パス | 必須 |
| `--driven_audio` | 入力音声ファイル (WAV/MP3) | 必須 |
| `--result_dir` | 出力ディレクトリ | ./results |

### 処理パラメータ

| パラメータ | 説明 | デフォルト |
|------------|------|------------|
| `--preprocess` | 画像前処理：crop, resize, full | full |
| `--size` | 画像サイズ：256, 512 | 256 |
| `--pose_style` | ポーズスタイル 0-45 | 0 |
| `--expression_scale` | 表情強度 0.5-1.5 | 1.0 |

### 画質向上パラメータ

| パラメータ | 説明 | デフォルト |
|------------|------|------------|
| `--enhancer` | 顔画質向上：gfpgan, RestoreFormer, CodeFormer | なし |

### パフォーマンスパラメータ

| パラメータ | 説明 | デフォルト |
|------------|------|------------|
| `--batch_size` | バッチサイズ | 1 |
| `--fps` | 出力動画フレームレート | 25 |

## 使用例

### 例1：基本的な生成

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/basic
```

### 例2：GFPGAN画質向上

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/enhanced \
  --enhancer gfpgan
```

### 例3：カスタムポーズ

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/pose5 \
  --pose_style 5
```

### 例4：高解像度

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/hd \
  --size 512 \
  --enhancer gfpgan
```

## Python API

### 基本的な使用方法

```python
from inference import DragonTalker

# DragonTalkerの初期化
dragon = DragonTalker()

# 動画の生成
video_path = dragon.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="full",
    enhancer="gfpgan"
)

print(f"動画保存先: {video_path}")
```

### 高度な使用方法

```python
from inference import DragonTalker
import torch

# カスタム設定で初期化
dragon = DragonTalker(
    checkpoint_path="checkpoints/DragonTalker.pth",
    config_path="config/DragonTalker.yaml",
    device="cuda" if torch.cuda.is_available() else "cpu"
)

# 詳細オプション付きで動画を生成
video_path = dragon.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="full",
    pose_style=10,
    expression_scale=1.2,
    enhancer="gfpgan",
    batch_size=1,
    output_video="output.mp4"
)
```

### バッチ処理

```python
from inference import DragonTalker
import os

dragon = DragonTalker()

# 複数画像の処理（同じ音声を使用）
audio_file = "audio.wav"
image_dir = "images/"

for image_file in os.listdir(image_dir):
    if image_file.endswith(('.jpg', '.png')):
        output_path = f"results/{image_file}"
        dragon.generate(
            source_image=os.path.join(image_dir, image_file),
            driven_audio=audio_file,
            preprocess="full"
        )
```

## Webインターフェース

### Webデモの実行

```bash
python app.py
```

ブラウザで http://localhost:8888 を開いてください

### Webインターフェースの機能

1. **画像アップロード** - ポートレート画像をドラッグ＆ドロップ
2. **音声アップロード** - 音声ファイルを選択（WAV/MP3）
3. **プレビュー** - ソース画像と音声をプレビュー
4. **パラメータ調整** - ポーズ、表情、エンハンサーを調整
5. **生成** - ワンクリックで動画を生成
6. **ダウンロード** - 生成した動画を保存

## 顔画質向上エンハンサー

### 利用可能なエンハンサー

| エンハンサー | 品質 | 速度 | VRAM |
|--------------|------|------|------|
| なし | 基本的 | 高速 | 低 |
| gfpgan | 良好 | 中程度 | 中程度 |
| RestoreFormer | 非常に良好 | 遅い | 高 |
| CodeFormer | 非常に良好 | 遅い | 高 |

### 推奨

- **低VRAM**：エンハンサーなし または gfpgan
- **バランス**：gfpgan
- **最高品質**：RestoreFormer または CodeFormer

## 前処理モード

| モード | 説明 | ユースケース |
|--------|------|--------------|
| crop | 顔を中央で切り抜き | 高速処理 |
| resize | 目標サイズにリサイズ | シンプルな背景 |
| full | 完全な処理パイプライン | 最高品質 |

## 入力要件

### 画像要件

- 形式：JPG、PNG
- 解像度：512x512以上を推奨
- 顔：正面、無遮挡
- 背景：シンプルであることが望ましい

### 音声要件

- 形式：WAV、MP3
- 長さ：1-60秒
- サンプルレート：16000-48000 Hz
- 音声：明確、騒音最少

## 出力

### 動画形式

- 形式：MP4
- コーデック：H.264
- 解像度：256x256 または 512x512
- フレームレート：25
- ビットレート：2-5 Mbps

### 出力ディレクトリ

結果は指定した出力ディレクトリに保存されます：
```
results/
├── video.mp4          # 生成された動画
└── (一時ファイル)
```

## トラブルシューティング

### 動画が暗すぎる/明るすぎる

**原因：** トレーニングと入力の間の照明の不一致

**解決策：**
- expression_scaleパラメータを調整 (0.8-1.2)
- より高品質なソース画像を使用
- 異なるエンハンサーを試す

### 唇的不同期

**原因：** 音声品質または整合の問題

**解決策：**
- 高品質な音声を使用
- 音声が明確なSpeechを含むことを確認
- 音声と動画同期を確認

### 顔が変形する

**原因：** 入力品質が低い、または入力に問題がある

**解決策：**
- より高解像度の画像を使用 (512)
- 異なる前処理モードを試す
- 顔エンハンサーを使用
- 顔が明確に映っていることを確認

### 処理が遅い

**解決策：**
- `--preprocess crop` を使用
- `--size 256` を設定
- エンハンサーを無効化
- バッチサイズを削減

### GPUメモリ不足

**解決策：**
- batch_size を 1 に削減
- より小さい画像サイズを使用
- 他のGPUアプリケーションを閉じる

## パフォーマンスのヒント

### より高速な処理

1. `--preprocess crop` を使用
2. `--size 256` を設定
3. エンハンサーを無効化

### より高品質

1. `--size 512` を使用
2. `--enhancer gfpgan` を有効化
3. `--preprocess full` を使用

## 関連リンク

- [GitHub](https://github.com/your-repo/DragonTalker)
- [HuggingFace](https://huggingface.co/spaces)
- [モデル](https://github.com/your-repo/DragonTalker/releases)
