# DragonTalker 사용 가이드

DragonTalker은 단일 이미지 및 오디오 입력에서 사실적인 talking head 비디오를 생성하는 딥러닝을 사용합니다.

## 빠른 시작

### 기본 명령

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results
```

### 향상된 기능 포함

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results \
  --preprocess full \
  --enhancer gfpgan
```

## 명령 매개변수

### 입력 매개변수

| 매개변수 | 설명 | 기본값 |
|---------|------|-------|
| `--source_image` | 입력 초상 이미지 경로 | 필수 |
| `--driven_audio` | 입력 오디오 파일 경로 (WAV/MP3) | 필수 |
| `--result_dir` | 출력 디렉토리 | ./results |

### 처리 매개변수

| 매개변수 | 설명 | 기본값 |
|---------|------|-------|
| `--preprocess` | 이미지 전처리: crop, resize, full | full |
| `--size` | 이미지 크기: 256, 512 | 256 |
| `--pose_style` | 자세 스타일 0-45 | 0 |
| `--expression_scale` | 표현 강도 0.5-1.5 | 1.0 |

### 향상 매개변수

| 매개변수 | 설명 | 기본값 |
|---------|------|-------|
| `--enhancer` | 얼굴 향상기: gfpgan, RestoreFormer, CodeFormer | 없음 |

## 사용 예

### 예제 1: 기본 생성

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/basic
```

### 예제 2: GFPGAN 향상

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/enhanced \
  --enhancer gfpgan
```

## 입력 요구 사항

### 이미지 요구 사항

- 형식: JPG, PNG
- 해상도: 512x512 이상 권장
- 얼굴: 정면,遮挡 없음
- 배경: 단순할수록 좋음

### 오디오 요구 사항

- 형식: WAV, MP3
- 재생 시간: 1-60초
- 샘플 레이트: 16000-48000 Hz
- 음성: 선명, 최소 노이즈

## 출력

### 비디오 형식

- 형식: MP4
- 코덱: H.264
- 해상도: 256x256 또는 512x512
- 프레임 속도: 25
- 비트레이트: 2-5 Mbps

## 관련 링크

- [GitHub](https://github.com/your-repo/DragonTalker)
