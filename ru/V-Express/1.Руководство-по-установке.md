# V-Express Руководство по установке

V-Express — это метод генерации портретных видео, разработанный Tencent AI Lab. Он создаёт видео говорящих голов под управлением референсного изображения, аудио и последовательностей V-Kps.

## Обзор версий

| Версия | Статус | Описание |
|--------|--------|----------|
| V-Express 1.x | Текущая | Основной выпуск |

## Системные требования

### Аппаратные требования

| Компонент | Минимум | Рекомендуется |
|-----------|---------|---------------|
| GPU | NVIDIA 16GB VRAM | NVIDIA 24GB+ VRAM |
| RAM | 16GB | 32GB+ |
| Накопитель | 50GB | 100GB+ |
| CUDA | 11.8+ | 12.1+ |

### Программные требования

| Программа | Версия | Примечания |
|-----------|--------|------------|
| Python | 3.8 - 3.10 | Рекомендуется 3.9 |
| CUDA | 11.8+ | Требуется ускорение GPU |
| cuDNN | 8.5+ | Требуется для CUDA |
| ffmpeg | Последняя | Требуется для обработки видео |

## Установка в Linux/Ubuntu

### Шаг 1: Установка системных зависимостей

```bash
# Обновление системы
sudo apt update && sudo apt upgrade -y

# Установка Python и инструментов разработки
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Установка системных библиотек
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# Установка ffmpeg
sudo apt install ffmpeg

# Установка git-lfs
sudo apt install git-lfs
```

### Шаг 2: Клонирование проекта

```bash
git clone https://github.com/tencent-ailab/V-Express.git
cd V-Express
```

### Шаг 3: Создание виртуальной среды

```bash
python3.9 -m venv venv
source venv/bin/activate

# Проверка версии Python
python --version
```

### Шаг 4: Установка PyTorch

```bash
# Версия CUDA 11.8
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Проверка установки
python -c "import torch; print(torch.cuda.is_available())"
```

### Шаг 5: Установка зависимостей

```bash
pip install -r requirements.txt
```

### Шаг 6: Загрузка моделей

```bash
# Установка git-lfs
git lfs install

# Клонирование моделей с HuggingFace
git clone https://huggingface.co/tk93/V-Express

# Перемещение моделей в правильное расположение
mv V-Express/model_ckpts model_ckpts
mv V-Express/*.bin model_ckpts/v-express
```

Альтернативно, загрузить модели по отдельности:

```bash
# Создание директории для моделей
mkdir -p model_ckpts

# Загрузка требуемых моделей:
# - stabilityai/sd-vae-ft-mse
# - run wayml/stable-diffusion-v1-5 (только конфиг unet)
# - facebook/wav2vec2-base-960h
# - insightface/buffalo_l
```

## Установка в Windows

### Шаг 1: Установка Python

1. Скачать Python 3.9 с python.org
2. При установке отметить "Add Python to PATH"
3. Проверить: `python --version`

### Шаг 2: Установка CUDA

1. Скачать CUDA 11.8 с сайта NVIDIA
2. Установить с настройками по умолчанию
3. Скачать и установить cuDNN 8.9

### Шаг 3: Клонирование и настройка

```powershell
git clone https://github.com/tencent-ailab/V-Express.git
cd V-Express

python -m venv venv
venv\Scripts\activate
```

### Шаг 4: Установка зависимостей

```powershell
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Шаг 5: Загрузка моделей

Скачать модели с HuggingFace и поместить в директорию `model_ckpts/`.

## Установка в macOS

### Шаг 1: Установка зависимостей

```bash
# Установка Homebrew (если не установлен)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Установка Python и ffmpeg
brew install python@3.9 ffmpeg git git-lfs
```

### Шаг 2: Настройка

```bash
git clone https://github.com/tencent-ailab/V-Express.git
cd V-Express

python3.9 -m venv venv
source venv/bin/activate

# Установка PyTorch (только CPU на macOS)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Примечание: macOS поддерживает только режим CPU, ускорение GPU недоступно.

## Проверка установки

```bash
# Тестирование базовой функциональности
python inference.py --help
```

## Распространённые проблемы

### Недостаточно памяти CUDA

**Решения:**
- Уменьшить шаги вывода: `--num_inference_steps 15`
- Включить экономию памяти: `--save_gpu_memory`
- Использовать меньшее разрешение

### Отсутствуют библиотеки (Windows)

**Решения:**
- Установить Visual C++ Redistributable 2015-2022
- Добавить CUDA в системный PATH

### Ошибка загрузки моделей

**Решения:**
- Использовать VPN или прокси
- Скачать вручную с HuggingFace
- Проверить сетевое подключение

### ffmpeg не найден

**Решения:**
- Linux: `sudo apt install ffmpeg`
- Windows: Добавить ffmpeg в PATH
- macOS: `brew install ffmpeg`

## Важные примечания

1. **Ретаргетинг лица**: Когда целевое видео — это не тот же человек, что на референсном изображении, ретаргетинг лица важен. Выбирайте целевое видео с позой, более похожей на референсное лицо, для лучших результатов.

2. **Поддержка языков**: Модель лучше работает на английском языке; другие языки детально не тестировались.

3. **Качество изображения**: Используйте чёткие квадратные изображения лица с разрешением не менее 512x512.

## Ссылки

- [GitHub репозиторий](https://github.com/tencent-ailab/V-Express)
- [HuggingFace модели](https://huggingface.co/tk93/V-Express)
- [Статья](https://arxiv.org/abs/2406.02511)
- [Страница проекта](https://tenvence.github.io/p/v-express/)
