# DragonTalker ユーザーマニュアル

> DragonTalkerの機能使用方法と開発ガイドを詳しく説明
> 
> 更新日：2026年2月

---

## 一、機能概要

DragonTalkerは、深層学習ベースのトークンヘッド生成システムです。単一の静的な人物画像と音声ファイルを組み合わせて、人物の話し動作動画像を生成します。高度な3D顔再構成と画像合成アルゴリズムにより、元の人物の顔の特徴を維持しながら、自然な唇同期と表情の変化を実現します。

### 1.1 対応シーン

- **仮想主播**：仮想アバターにリアルな声と表情を設定
- **デジタル人客服**：擬人化されたインタラクティブ動画を生成
- **教育研修**：コースコンテンツを動画像形式で表示
- **映画・TV声優**： Quickly generate配音アニメーション

---

## 二、クイックスタート

### 2.1 基本的な使い方

```bash
source venv/bin/activate
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results
```

### 2.2 パラメータ説明

| パラメータ | 説明 | デフォルト |
|------|------|----------|
| --source_image | 入力源人物画像パス | 必需 |
| --driven_audio | 入力駆動音声パス | 必需 |
| --result_dir | 出力動画保存ディレクトリ | ./results |
| --enhancer | 顔強調アルゴリズム | gfpgan |
| --outputfps | 出力動画フレームレート | 25 |

---

## 三、入出力仕様

### 3.1 源画像要件

- 形式：JPG、PNG
- 解像度：推奨512×512以上
- 内容：正面顔、クリア、遮蔽なし

### 3.2 駆動音声要件

- 形式：WAV、MP3
- 長さ：1-60秒
- 品質：クリアな音声

### 3.3 出力動画仕様

- 形式：MP4 (H.264)
- 解像度：256×256 または 512×512
- フレームレート：25 FPS

---

## 四、Webインターフェース

DragonTalkerはWebGUIを提供し、非技術ユーザーにも優しい設計です。

```bash
python app.py
```

ブラウザで http://localhost:7860 にアクセス

---

## 五、Python API

### 5.1 基本的な使い方

```python
from dragon_talker import DragonTalker

model = DragonTalker(
    device='cuda',
    faceid_weight=0.5,
    enhancer='gfpgan'
)

model.load_source('source.jpg')
model.load_audio('audio.wav')

result_path = model.generate(
    output_path='result.mp4',
    preprocess='full',
    fps=25
)

print(f"動画を保存しました: {result_path}")
```

---

## 六、FAQ

### 6.1 動画质量问题

**生成された顔がぼやけている**

解決方案：顔強調機能を有効に

```bash
python inference.py --enhancer gfpgan ...
```

---

**唇と音声的不同步**

原因：音声品質が悪いまたは話し速度が速すぎる

解決方案：
1. 音声を前処理、サンプルレートを向上
2. よりクリアな音声ソースを使用

---

### 6.2 パフォーマンス問題

**GPUメモリ不足**

解決方案：
1. 出力解像度を減らす：`--output_size 256`
2. 強調機能を無効に：`--enhancer none`
3. CPUモードを使用：`--device cpu`

---

## 七、関連リソース

- デモ：https://huggingface.co/spaces/dragon-talker
- GitHub：https://github.com/your-repo/DragonTalker
