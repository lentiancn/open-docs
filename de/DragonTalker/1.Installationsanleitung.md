# DragonTalker Installationsanleitung

DragonTalker ist ein KI-Projekt zur Erstellung realistischer Sprechkopfvideos aus einem einzelnen Bild und Audio, ähnlich wie SadTalker. Es verwendet Deep Learning, um statische Bilder mit audio-gesteuerten Gesichtsbewegungen zu animieren.

## Versionsübersicht

| Version | Status | Beschreibung |
|---------|--------|-------------|
| DragonTalker 1.x | Aktuell | Hauptversion |

**Hinweis:** DragonTalker ist eine aufkommende Technologie. Für ausgereiftere Lösungen sollten Sie SadTalker oder Wav2Lip in Betracht ziehen.

## Systemanforderungen

### Hardwareanforderungen

| Komponente | Minimum | Empfohlen |
|------------|---------|------------|
| GPU | NVIDIA 6GB VRAM | NVIDIA 16GB VRAM |
| RAM | 8GB | 32GB |
| Speicher | 20GB | 50GB |
| CUDA | 11.7+ | 11.8+ |

### Softwareanforderungen

| Software | Version | Hinweise |
|----------|---------|----------|
| Python | 3.8 - 3.10 | 3.9 empfohlen |
| CUDA | 11.7+ | GPU-Beschleunigung erforderlich |
| cuDNN | 8.5+ | Für CUDA erforderlich |
| ffmpeg | Neueste Version | Für Videoverarbeitung erforderlich |

## Linux/Ubuntu Installation

### Schritt 1: Systemabhängigkeiten installieren

```bash
# System aktualisieren
sudo apt update && sudo apt upgrade -y

# Python und Entwicklungstools installieren
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Systembibliotheken installieren
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# ffmpeg installieren
sudo apt install ffmpeg
```

### Schritt 2: CUDA installieren (falls erforderlich)

```bash
# CUDA 11.8 herunterladen und installieren
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

### Schritt 3: Projekt klonen

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker
```

### Schritt 4: Virtuelle Umgebung erstellen

```bash
python3.9 -m venv venv
source venv/bin/activate

# Python-Version überprüfen
python --version
```

### Schritt 5: PyTorch installieren

```bash
# CUDA 11.8 Version
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Installation überprüfen
python -c "import torch; print(torch.cuda.is_available())"
```

### Schritt 6: Abhängigkeiten installieren

```bash
pip install -r requirements.txt

# Zusätzliche Abhängigkeiten installieren
pip install numpy opencv-python librosa soundfile
```

### Schritt 7: Modelle herunterladen

```bash
# Modellverzeichnis erstellen
mkdir -p checkpoints

# Modelle herunterladen (Projektanweisungen beachten)
# bash scripts/download_models.sh
```

## Windows Installation

### Schritt 1: Python installieren

1. Python 3.9 von python.org herunterladen
2. "Add Python to PATH" während der Installation aktivieren
3. Überprüfen: `python --version`

### Schritt 2: CUDA installieren

1. CUDA 11.8 von der NVIDIA-Website herunterladen
2. Mit Standardeinstellungen installieren
3. cuDNN 8.9 herunterladen und installieren

### Schritt 3: Klonen und einrichten

```powershell
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python -m venv venv
venv\Scripts\activate
```

### Schritt 4: Abhängigkeiten installieren

```powershell
# PyTorch installieren (mit CUDA-Unterstützung)
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Schritt 5: Modelle herunterladen

Modelle von der Projekt-Release-Seite herunterladen und im `checkpoints/`-Verzeichnis ablegen.

## macOS Installation

### Schritt 1: Abhängigkeiten installieren

```bash
# Homebrew installieren (falls nicht vorhanden)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Python und ffmpeg installieren
brew install python@3.9 ffmpeg git
```

### Schritt 2: Einrichten

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python3.9 -m venv venv
source venv/bin/activate

# PyTorch installieren (macOS nur CPU)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Hinweis: macOS unterstützt nur den CPU-Modus, GPU-Beschleunigung ist nicht möglich.

## Docker Installation

### Docker verwenden

```bash
# Image herunterladen
docker pull your-registry/dragontalker:latest

# Ausführen (GPU erforderlich)
docker run --gpus all -v $(pwd):/workspace -p 8888:8888 your-registry/dragontalker:latest
```

### Docker Compose verwenden

```yaml
version: '3.8'
services:
  dragontalker:
    image: your-registry/dragontalker:latest
    volumes:
      - ./workspace:/workspace
    ports:
      - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## Installation überprüfen

```bash
# Grundfunktionalität testen
python inference.py --help
```

## Häufige Probleme

### CUDA Speicher voll

**Lösungen:**
- Batch-Größe reduzieren: `--batch_size 1`
- Niedrigere Auflösung verwenden: `--size 256`
- Modell-Offloading aktivieren

### Fehlende Bibliotheken (Windows)

**Lösungen:**
- Visual C++ Redistributable 2015-2022 installieren
- CUDA zum System-PATH hinzufügen

### Modell-Download fehlgeschlagen

**Lösungen:**
- VPN oder Proxy verwenden
- Manuell von GitHub Releases herunterladen
- Netzwerkverbindung überprüfen

### ffmpeg nicht gefunden

**Lösungen:**
- Linux: `sudo apt install ffmpeg`
- Windows: ffmpeg zum PATH hinzufügen
- macOS: `brew install ffmpeg`

## Verwandte Links

- [GitHub-Repository](https://github.com/your-repo/DragonTalker)
- [HuggingFace Demo](https://huggingface.co/spaces)
- [Modell-Downloads](https://github.com/your-repo/DragonTalker/releases)
