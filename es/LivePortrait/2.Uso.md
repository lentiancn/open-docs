# Guía de uso de LivePortrait

LivePortrait es un marco eficiente de animación de retratos que anima retratos estáticos utilizando el movimiento de videos de conducción. Soporta control de costuras y reenmarcado.

## Inicio rápido

### Comando básico

```bash
# Animación impulsada por video
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir ./results
```

### Con costuras

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir ./results \
  --stitching
```

### Con reenmarcado de ojos/labios

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results \
  --eye_retargeting 0.5 \
  --lip_retargeting 0.5
```

## Parámetros de comando

### Parámetros de entrada

| Parámetro | Descripción | Valor predeterminado |
|-----------|-------------|---------------------|
| `--source_image` | Ruta de imagen de retrato de entrada | Requerido |
| `--driving_video` | Ruta del video de conducción | Opcional |
| `--driven_audio` | Ruta del audio de conducción | Opcional |
| `--result_dir` | Directorio de salida | ./results |

### Parámetros de procesamiento

| Parámetro | Descripción | Valor predeterminado |
|-----------|-------------|---------------------|
| `--stitching` | Habilitar costuras | False |
| `--eye_retargeting` | Reenmarcado de ojos (0-1) | 0 |
| `--lip_retargeting` | Reenmarcado de labios (0-1) | 0 |
| `--face_parser` | Habilitar análisis facial | True |

### Parámetros de rendimiento

| Parámetro | Descripción | Valor predeterminado |
|-----------|-------------|---------------------|
| `--batch_size` | Tamaño de lote | 1 |
| `--fps` | Velocidad de fotogramas del video de salida | 30 |

## Ejemplos de uso

### Ejemplo 1: Animación básica impulsada por video

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/basic
```

### Ejemplo 2: Con costuras

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/stitching \
  --stitching
```

### Ejemplo 3: Control de ojos

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/eyes \
  --eye_retargeting 0.8
```

### Ejemplo 4: Control de sincronización de labios

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/lips \
  --lip_retargeting 0.7
```

### Ejemplo 5: Control completo

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driving_video examples/driving_video.mp4 \
  --result_dir results/full \
  --stitching \
  --eye_retargeting 0.5 \
  --lip_retargeting 0.5
```

## API de Python

### Uso básico

```python
from liveportrait import LivePortrait

# Inicializar
lp = LivePortrait()

# Animar retrato
result = lp.animate(
    source_image="image.jpg",
    driving_video="video.mp4",
    stitching=True,
    eye_retargeting=0.5,
    lip_retargeting=0.5
)

print(f"Video guardado en: {result}")
```

### Uso avanzado

```python
from liveportrait import LivePortrait
import torch

# Inicializar con configuración personalizada
lp = LivePortrait(
    checkpoint_path="pretrained_models/liveportrait.pth",
    device="cuda" if torch.cuda.is_available() else "cpu"
)

# Generar con control completo
result = lp.animate(
    source_image="image.jpg",
    driving_video="video.mp4",
    stitching=True,
    eye_retargeting=0.8,
    lip_retargeting=0.8,
    output_fps=30,
    output_resolution=(512, 512)
)
```

### Procesamiento por lotes

```python
from liveportrait import LivePortrait
import os

lp = LivePortrait()

# Procesar múltiples imágenes
source_dir = "source_images/"
driving_video = "driving.mp4"

for image_file in os.listdir(source_dir):
    if image_file.endswith(('.jpg', '.png')):
        result = lp.animate(
            source_image=os.path.join(source_dir, image_file),
            driving_video=driving_video,
            stitching=True
        )
```

## Interfaz web

### Ejecutar demo web

```bash
python app.py
```

Luego abrir http://localhost:7860 en el navegador

### Funciones de la interfaz web

1. **Subir imagen de origen** - Subir imagen de retrato
2. **Subir video de conducción** - Seleccionar video de conducción
3. **Interruptor de costuras** - Habilitar/deshabilitar costuras
4. **Control de ojos** - Ajustar intensidad del movimiento de ojos
5. **Control de labios** - Ajustar intensidad de sincronización de labios
6. **Generar** - Crear animación
7. **Descargar** - Guardar resultado

## Características

### 1. Costuras

El módulo de costuras conecta la cabeza generada con el cuerpo de manera perfecta:

```bash
--stitching
```

- Transición suave entre cabeza y cuerpo
- Funciona con varios estilos de imagen (realista, óleo, escultura, 3D)

### 2. Reenmarcado de ojos

Controla la apertura de los ojos con un valor escalar (0-1):

```bash
--eye_retargeting 0.5
```

- 0: Ojos cerrados
- 1: Ojos completamente abiertos
- 0.5: Natural

### 3. Reenmarcado de labios

Controla la intensidad del movimiento de labios:

```bash
--lip_retargeting 0.5
```

- 0: Movimiento mínimo
- 1: Movimiento máximo
- 0.5: Natural

## Requisitos de entrada

### Imagen de origen

- Formato: JPG, PNG
- Resolución: 512x512 o superior recomendado
- Cara: Frontal, clara
- Fondo: Cualquiera

### Video de conducción

- Formato: MP4, AVI
- Duración: 1-60 segundos
- Resolución: Cualquiera
- Cara: Expresiones faciales claras

## Salida

### Formato de video

- Formato: MP4
- Códec: H.264
- Resolución: 512x512
- Velocidad de fotogramas: 30

### Directorio de salida

```
results/
├── output.mp4          # Video generado
└── (archivos temporales)
```

## Solución de problemas

### Mala calidad de animación

**Soluciones:**
- Usar imagen de origen de mayor calidad
- Asegurarse de que el video de conducción tenga cara clara
- Ajustar parámetros de reenmarcado

### Cara no detectada

**Soluciones:**
- Usar imagen de retrato más clara
- Asegurarse de que la cara sea visible
- Verificar formato de imagen

### Procesamiento lento

**Soluciones:**
- Reducir resolución de salida
- Deshabilitar costuras si no es necesario
- Usar aceleración GPU

### Memoria GPU insuficiente

**Soluciones:**
- Reducir tamaño de lote a 1
- Usar tamaño de imagen más pequeño
- Cerrar otras aplicaciones GPU

## Consejos de rendimiento

### Procesamiento más rápido

1. Deshabilitar costuras si no es necesario
2. Usar menor resolución de salida
3. Reducir fps

### Mejor calidad

1. Habilitar costuras
2. Usar imagen de origen de alta calidad
3. Ajustar parámetros de reenmarcado

## Enlaces relacionados

- [GitHub](https://github.com/KwaiVGI/LivePortrait)
- [Artículo](https://arxiv.org/abs/2407.03168)
- [Demo](https://liveportrait.github.io)
