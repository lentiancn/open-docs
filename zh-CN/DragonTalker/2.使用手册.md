# DragonTalker 使用手册

> 详细说明 DragonTalker 的功能使用方法和开发指南
> 
> 更新日期：2026年2月

---

## 一、功能概述

DragonTalker 是一款基于深度学习的说话头像生成系统，其核心功能是将一张静态人物图像与一段音频文件相结合，生成人物说话动作的动态视频。该技术基于先进的3D面部重建和图像合成算法，能够保持原始人物的面部特征，同时实现自然的唇形同步和表情变化。

### 1.1 支持的应用场景

- **虚拟主播**：为虚拟形象配置真实的声音和表情
- **数字人客服**：生成拟人化的交互视频
- **教育培训**：将课程内容以动态视频形式呈现
- **影视配音**：为角色快速生成配音动画
- **已故亲人重现**：使用历史照片和音频合成影像（需授权）

### 1.2 技术特点

- 高度逼真：生成的面部表情自然流畅，难以分辨真伪
- 快速生成：单张图像和音频在几分钟内即可完成处理
- 姿态多样：支持多种头部姿势和面部表情变化
- 质量可选：可根据需求选择不同的画质增强级别

---

## 二、快速开始

### 2.1 基本用法

安装完成后，最简单的使用方式是运行命令行推理：

```bash
# 激活虚拟环境
source venv/bin/activate  # Linux/macOS
# 或
venv\Scripts\activate     # Windows

# 运行推理脚本
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results
```

### 2.2 参数说明

| 参数 | 简写 | 说明 | 默认值 |
|------|------|------|----------|
| --source_image | -i | 输入的源人物图像路径 | 必需 |
| --driven_audio | -a | 输入的驱动音频路径 | 必需 |
| --result_dir | -o | 输出视频保存目录 | ./results |
| --preprocess | -p | 图像预处理模式 | full |
| --enhancer | -e | 面部增强算法 | gfpgan |
| --outputfps | -f | 输出视频帧率 | 25 |
| --faceid_weight | -w | 身份保持权重 | 0.5 |

### 2.3 预处理模式

| 模式 | 说明 | 适用场景 |
|------|------|----------|
| full | 完整预处理，包括面部对齐和光照调整 | 通用场景 |
| crop | 仅裁剪人脸区域 | 人脸占比大的图像 |
| resize | 仅调整分辨率 | 快速预览 |

### 2.4 增强算法

| 算法 | 效果 | 速度 | 显存需求 |
|------|------|------|----------|
| gfpgan | 较好的整体修复效果 | 快 | 2GB |
| restoreformer | 精细的面部细节 | 中等 | 4GB |
| codeformer | 平衡质量和速度 | 中等 | 3GB |
| none | 不使用增强 | 最快 | 0 |

---

## 三、输入输出规格

### 3.1 源图像要求

**文件格式**：支持 JPG、PNG、BMP 等常见图像格式，推荐使用 PNG 以获得最佳画质

**分辨率要求**：
- 最低：256×256 像素
- 推荐：512×512 像素或更高
- 最优：1024×1024 像素

**图像内容**：
- 人脸应占据画面主体区域
- 推荐使用正面免冠照片
- 面部特征清晰，无大面积遮挡
- 光照均匀，避免极端背光或侧光
- 表情自然，推荐中性表情

**图像示例**：

```
正确示例：
├── 正脸照片.jpg       # 正面免冠，表情自然
├── 证件照.png        # 光照均匀，质量高
└── 艺术照.png       # 背景简洁

错误示例：
├── 侧脸照片.jpg       # 侧脸角度过大
├── 遮挡照片.jpg       # 墨镜、口罩等遮挡
├── 模糊照片.jpg      # 运动模糊或失焦
└── 多人照片.jpg      # 包含多个面部
```

### 3.2 驱动音频要求

**文件格式**：支持 WAV、MP3、M4A、AAC 等主流音频格式

**音频特性**：
- 采样率：推荐 16kHz 或 44.1kHz
- 时长：1秒至60秒为宜
- 内容：清晰的人声语音
- 编码：推荐使用 PCM 或 MP3 编码

**音频预处理**：

如音频不符合要求，可使用 ffmpeg 进行预处理：

```bash
# 转换格式
ffmpeg -i input.wav -ar 16000 output.wav

# 裁剪时长
ffmpeg -i input.wav -ss 0 -t 30 output.wav

# 降噪（可选）
ffmpeg -i input.wav -af "anoisesrc=p=-30" output.wav
```

### 3.3 输出视频规格

| 参数 | 可选值 | 默认值 |
|------|--------|----------|
| 视频格式 | MP4 (H.264) | MP4 |
| 分辨率 | 256×256, 512×512 | 256×256 |
| 帧率 | 25, 30, 60 | 25 |
| 视频码率 | 1M, 2M, 4M | 2M |

---

## 四、Web 界面使用

DragonTalker 提供 Web 图形界面，方便非技术用户使用。

### 4.1 启动 Web 服务

```bash
# 启动Web服务，默认端口7860
python app.py

# 指定端口
python app.py --port 8080

# 允许局域网访问
python app.py --share true
```

### 4.2 界面功能

打开浏览器访问 `http://localhost:7860`，界面包含以下功能区域：

1. **图像上传区**：拖拽或点击上传源人物图像
2. **音频上传区**：上传驱动音频文件
3. **参数设置区**：调整生成参数
4. **预览区**：查看生成结果
5. **下载区**：保存生成的视频

### 4.3 批量处理

Web界面支持批量上传多段音频，自动依次处理：

```bash
# 批量处理
python batch_inference.py \
  --source_image examples/source.jpg \
  --audio_dir ./audios \
  --output_dir ./batch_results
```

---

## 五、Python API 使用

DragonTalker 提供完整的 Python API，支持程序化调用和二次开发。

### 5.1 基本调用流程

```python
from dragon_talker import DragonTalker

# 初始化模型
model = DragonTalker(
    device='cuda',           # 使用GPU加速
    faceid_weight=0.5,       # 身份保持权重
    enhancer='gfpgan'         # 面部增强算法
)

# 加载图像和音频
model.load_source('source.jpg')
model.load_audio('audio.wav')

# 生成视频
result_path = model.generate(
    output_path='result.mp4',
    preprocess='full',
    fps=25
)

print(f"视频已保存至: {result_path}")
```

### 5.2 高级用法

```python
from dragon_talker import DragonTalker, FaceDetector, AudioProcessor

# 自定义人脸检测器
face_detector = FaceDetector(
    model='retinaface',
    device='cuda'
)

# 自定义音频处理器
audio_processor = AudioProcessor(
    sample_rate=16000,
    normalize=True
)

# 组合使用
model = DragonTalker(
    face_detector=face_detector,
    audio_processor=audio_processor
)
```

### 5.3 返回值处理

```python
# 生成结果包含详细信息
result = model.generate(return_dict=True)

print(f"视频路径: {result['video_path']}")
print(f"处理耗时: {result['processing_time']:.2f}秒")
print(f"生成帧数: {result['total_frames']}")
print(f"平均FPS: {result['avg_fps']:.1f}")
```

---

## 六、自定义训练

如需训练自定义模型，请参考以下步骤：

### 6.1 数据准备

训练数据目录结构：

```
dataset/
├── train/
│   ├── videos/
│   │   ├── person001/
│   │   │   ├── video001.mp4
│   │   │   └── video002.mp4
│   │   └── person002/
│   └── audios/
│       ├── person001/
│       └── person002/
└── val/
    └── (同上结构)
```

### 6.2 开始训练

```bash
# 单GPU训练
python train.py --config configs/train_base.yaml

# 多GPU训练
python -m torch.distributed.launch \
  --nproc_per_node=4 \
  train.py \
  --config configs/train_base.yaml
```

### 6.3 训练参数

| 参数 | 说明 | 常用值 |
|------|------|--------|
| --batch_size | 批处理大小 | 8-32 |
| --lr | 学习率 | 1e-4 |
| --epochs | 训练轮数 | 100-500 |
| --log_interval | 日志输出间隔 | 100 |

---

## 七、常见问题解答

### 7.1 视频质量类

**问题：生成的面部模糊不清晰**

解决方案：启用面部增强功能，使用 gfpgan 或 restoreformer 算法

```bash
python inference.py --enhancer gfpgan ...
```

---

**问题：唇形与音频不同步**

可能原因：音频质量差或语速过快

解决方案：
1. 预处理音频，提高采样率
2. 调整音频预处理参数
3. 使用更清晰的音频源

---

**问题：面部出现扭曲变形**

可能原因：源图像角度过大或表情夸张

解决方案：使用正面免冠照片作为源图像

---

### 7.2 性能类

**问题：GPU显存不足**

解决方案：
1. 减小输出分辨率：`--output_size 256`
2. 关闭增强功能：`--enhancer none`
3. 使用CPU模式：`--device cpu`（速度较慢）

---

**问题：处理速度太慢**

优化建议：
1. 使用GPU进行加速
2. 预先启动Web服务并保持模型加载状态
3. 批量处理时使用较长的预热时间

---

### 7.3 错误处理类

**问题：提示 "No face detected in source image"**

解决方案：
1. 检查图像中是否包含清晰的人脸
2. 确认图像格式正确
3. 尝试使用其他人脸图像

---

**问题：提示 "Audio processing failed"**

解决方案：
1. 确认音频文件格式正确
2. 使用 ffmpeg 转换音频格式
3. 检查音频是否包含有效语音内容

---

## 八、性能优化

### 8.1 显存优化

```python
# 使用混合精度推理
model = DragonTalker(
    precision='fp16',  # 半精度模式，显存减半
    tile_size=512     # 分块处理，大图不显存溢出
)
```

### 8.2 批量处理优化

```python
# 批量加载音频
from dragon_talker import AudioBatchLoader

loader = AudioBatchLoader(
    audio_dir='./audios',
    batch_size=10,
    preprocess=True
)

for batch in loader:
    results = model.generate_batch(batch)
```

### 8.3 分布式处理

对于大规模视频生成需求，可以使用多台机器分布式处理：

```bash
# 启动主节点
python distribute.py --master --port 22222

# 启动工作节点
python distribute.py --worker --master-addr 192.168.1.100:22222
```

---

## 九、API 参考

### 9.1 DragonTalker 类

```python
class DragonTalker:
    def __init__(self, device='cuda', faceid_weight=0.5, enhancer='gfpgan'):
        """初始化模型
        
        参数:
            device: 计算设备，'cuda' 或 'cpu'
            faceid_weight: 身份保持权重，0-1之间
            enhancer: 面部增强算法
        """
        
    def load_source(self, image_path):
        """加载源图像"""
        
    def load_audio(self, audio_path):
        """加载驱动音频"""
        
    def generate(self, output_path=None, preprocess='full', fps=25, return_dict=False):
        """生成说话视频
        
        返回:
            str 或 dict: 视频路径或详细信息字典
        """
```

### 9.2 配置项参考

详细配置参数请查阅 `config/default_config.yaml` 文件。

---

## 十、相关资源

- 官方演示：https://huggingface.co/spaces/dragon-talker
- 模型下载：自动从 HuggingFace Hub 下载
- 技术论文：查看 `docs/paper.md`
- 更新日志：查看 `CHANGELOG.md`
