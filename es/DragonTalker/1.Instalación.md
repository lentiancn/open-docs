# Guía de instalación de DragonTalker

DragonTalker es un proyecto de IA para generar videos realistas de cabezas parlantes a partir de una sola imagen y audio, similar a SadTalker. Utiliza aprendizaje profundo para animar imágenes estáticas con movimientos faciales controlados por audio.

## Versión general

| Versión | Estado | Descripción |
|---------|--------|-------------|
| DragonTalker 1.x | Actual | Versión principal |

**Nota:** DragonTalker es una tecnología emergente. Para soluciones más maduras, considere SadTalker o Wav2Lip.

## Requisitos del sistema

### Requisitos de hardware

| Componente | Mínimo | Recomendado |
|------------|---------|-------------|
| GPU | NVIDIA 6GB VRAM | NVIDIA 16GB VRAM |
| RAM | 8GB | 32GB |
| Almacenamiento | 20GB | 50GB |
| CUDA | 11.7+ | 11.8+ |

### Requisitos de software

| Software | Versión | Notas |
|----------|---------|-------|
| Python | 3.8 - 3.10 | Se recomienda 3.9 |
| CUDA | 11.7+ | Requiere aceleración GPU |
| cuDNN | 8.5+ | Requiere CUDA |
| ffmpeg | Última versión | Requiere procesamiento de video |

## Instalación en Linux/Ubuntu

### Paso 1: Instalar dependencias del sistema

```bash
# Actualizar sistema
sudo apt update && sudo apt upgrade -y

# Instalar Python y herramientas de desarrollo
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Instalar bibliotecas del sistema
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# Instalar ffmpeg
sudo apt install ffmpeg
```

### Paso 2: Instalar CUDA (si es necesario)

```bash
# Descargar e instalar CUDA 11.8
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

### Paso 3: Clonar proyecto

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker
```

### Paso 4: Crear entorno virtual

```bash
python3.9 -m venv venv
source venv/bin/activate

# Verificar versión de Python
python --version
```

### Paso 5: Instalar PyTorch

```bash
# Versión para CUDA 11.8
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Verificar instalación
python -c "import torch; print(torch.cuda.is_available())"
```

### Paso 6: Instalar dependencias

```bash
pip install -r requirements.txt

# Instalar dependencias adicionales
pip install numpy opencv-python librosa soundfile
```

### Paso 7: Descargar modelos

```bash
# Crear directorio de modelos
mkdir -p checkpoints

# Descargar modelos (consulte las instrucciones del proyecto)
# bash scripts/download_models.sh
```

## Instalación en Windows

### Paso 1: Instalar Python

1. Descargar Python 3.9 de python.org
2. Marcar "Add Python to PATH" durante la instalación
3. Verificar: `python --version`

### Paso 2: Instalar CUDA

1. Descargar CUDA 11.8 del sitio web de NVIDIA
2. Instalar con configuración predeterminada
3. Descargar e instalar cuDNN 8.9

### Paso 3: Clonar y configurar

```powershell
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python -m venv venv
venv\Scripts\activate
```

### Paso 4: Instalar dependencias

```powershell
# Instalar PyTorch (con soporte CUDA)
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Paso 5: Descargar modelos

Descargue los modelos de la página de lanzamientos del proyecto y colóquelos en el directorio `checkpoints/`.

## Instalación en macOS

### Paso 1: Instalar dependencias

```bash
# Instalar Homebrew (si no está instalado)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Instalar Python y ffmpeg
brew install python@3.9 ffmpeg git
```

### Paso 2: Configurar

```bash
git clone https://github.com/your-repo/DragonTalker.git
cd DragonTalker

python3.9 -m venv venv
source venv/bin/activate

# Instalar PyTorch (macOS solo CPU)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Nota: macOS solo admite modo CPU, no puede usar aceleración GPU.

## Instalación con Docker

### Usar Docker

```bash
# Descargar imagen
docker pull your-registry/dragontalker:latest

# Ejecutar (requiere GPU)
docker run --gpus all -v $(pwd):/workspace -p 8888:8888 your-registry/dragontalker:latest
```

### Usar Docker Compose

```yaml
version: '3.8'
services:
  dragontalker:
    image: your-registry/dragontalker:latest
    volumes:
      - ./workspace:/workspace
    ports:
      - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## Verificar instalación

```bash
# Probar funcionalidad básica
python inference.py --help
```

## Problemas comunes

### Memoria CUDA insuficiente

**Soluciones:**
- Reducir tamaño de lote: `--batch_size 1`
- Usar menor resolución: `--size 256`
- Habilitar descarga de modelo

### Bibliotecas faltantes (Windows)

**Soluciones:**
- Instalar Visual C++ Redistributable 2015-2022
- Agregar CUDA al PATH del sistema

### Error al descargar modelos

**Soluciones:**
- Usar VPN o proxy
- Descargar manualmente desde GitHub releases
- Verificar conexión de red

### ffmpeg no encontrado

**Soluciones:**
- Linux: `sudo apt install ffmpeg`
- Windows: Agregar ffmpeg al PATH
- macOS: `brew install ffmpeg`

## Enlaces relacionados

- [Repositorio de GitHub](https://github.com/your-repo/DragonTalker)
- [Demo de HuggingFace](https://huggingface.co/spaces)
- [Descargas de modelos](https://github.com/your-repo/DragonTalker/releases)
