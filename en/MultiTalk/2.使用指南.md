# MultiTalk Usage Guide

This guide covers how to use MultiTalk for generating multi-speaker audio content.

## Quick Start

### Basic Usage

```bash
python inference.py \
  --text "Hello everyone, welcome to MultiTalk." \
  --speakers speaker1,speaker2 \
  --output result.wav
```

## Input Requirements

### Text Requirements

- Language: Multi-language support
- Format: Plain text
- Length: No strict limit

### Speaker Configuration

Define speakers in `speakers.yaml`:

```yaml
speakers:
  speaker1:
    voice_id: "voice_001"
    language: "en"
  speaker2:
    voice_id: "voice_002"
    language: "en"
```

## Advanced Usage

### Custom Voice IDs

```bash
python inference.py \
  --text "This is a custom voice demo." \
  --voice_ids voice001,voice002 \
  --output output.wav
```

### Adjust Speed

```bash
python inference.py \
  --text "Slow speech example." \
  --speakers speaker1 \
  --speed 0.8 \
  --output slow.wav
```

### Batch Processing

```bash
python batch_inference.py \
  --text_file texts.txt \
  --output_dir output/
```

## Configuration

### Config File

Edit `config.yaml`:

```yaml
inference:
  sample_rate: 22050
  speed: 1.0
  
model:
  checkpoint: "checkpoints/multitalk.pth"
```

## Best Practices

### 1. Use Appropriate Voice IDs

Choose voice IDs that match the speaker characteristics.

### 2. Match Language

Ensure text language matches voice language.

### 3. Optimize Speed

Adjust speed for natural-sounding output.

## Troubleshooting

### Audio Quality Poor?

Try different voice IDs.

### Speed Issues?

Adjust speed parameter gradually.

## Related Resources

- [GitHub](https://github.com/MultiTalk/MultiTalk)
