# Guide d'utilisation SadTalker

SadTalker génère des vidéos réalistes de têtes parlantes à partir d'une seule image et d'une entrée audio en utilisant l'apprentissage profond.

## Démarrage rapide

### Commande de base

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results
```

### Générer une vidéo avec amélioration

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir ./results \
  --preprocess full \
  --enhancer gfpgan
```

## Paramètres de ligne de commande

### Paramètres d'entrée

| Paramètre | Description | Par défaut |
|-----------|-------------|------------|
| `--source_image` | Chemin de l'image portrait d'entrée | Requis |
| `--driven_audio` | Chemin du fichier audio d'entrée (WAV/MP3) | Requis |
| `--result_dir` | Répertoire de sortie | ./results |

### Paramètres de traitement

| Paramètre | Description | Par défaut |
|-----------|-------------|------------|
| `--preprocess` | Prétraitement de l'image : crop, resize, full | full |
| `--size` | Taille de l'image : 256, 512 | 256 |
| `--pose_style` | Style de pose 0-45 | 0 |
| `--expression_scale` | Intensité d'expression 0.5-1.5 | 1.0 |

### Paramètres d'amélioration

| Paramètre | Description | Par défaut |
|-----------|-------------|------------|
| `--enhancer` | Améliorateur facial : gfpgan, RestoreFormer, CodeFormer | Aucun |
| `--enhancer_background` | Améliorer l'arrière-plan | False |

### Paramètres de performance

| Paramètre | Description | Par défaut |
|-----------|-------------|------------|
| `--batch_size` | Taille du batch pour le traitement | 1 |
| `--fps` | IPS de la vidéo de sortie | 25 |
| `--faceid` | Garder l'identité du visage | False |

### Autres paramètres

| Paramètre | Description | Par défaut |
|-----------|-------------|------------|
| `--help` | Afficher toutes les options | - |

## Exemples d'utilisation

### Exemple 1 : Génération de base

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/basic
```

### Exemple 2 : Avec amélioration GFPGAN

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/enhanced \
  --enhancer gfpgan
```

### Exemple 3 : Style de pose personnalisé

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/pose5 \
  --pose_style 5
```

### Exemple 4 : Résolution plus élevée

```bash
python inference.py \
  --source_image examples/source_image.jpg \
  --driven_audio examples/driven_audio.wav \
  --result_dir results/hd \
  --size 512 \
  --enhancer gfpgan
```

## API Python

### Utilisation de base

```python
from inference import SadTalker

# Initialiser SadTalker
sadtalker = SadTalker()

# Générer une vidéo
video_path = sadtalker.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="full",
    enhancer="gfpgan"
)

print(f"Vidéo enregistrée dans : {video_path}")
```

### Utilisation avancée

```python
from inference import SadTalker
import torch

# Initialiser avec des paramètres personnalisés
sadtalker = SadTalker(
    checkpoint_path="checkpoints/SadTalker.pth",
    config_path="config/SadTalker.yaml",
    device="cuda" if torch.cuda.is_available() else "cpu"
)

# Générer avec des options avancées
video_path = sadtalker.generate(
    source_image="image.jpg",
    driven_audio="audio.wav",
    preprocess="full",
    pose_style=10,
    expression_scale=1.2,
    enhancer="gfpgan",
    batch_size=1,
    output_video="output.mp4"
)
```

### Traitement par lots

```python
from inference import SadTalker
import os

sadtalker = SadTalker()

# Traiter plusieurs images avec le même audio
audio_file = "audio.wav"
image_dir = "images/"

for image_file in os.listdir(image_dir):
    if image_file.endswith(('.jpg', '.png')):
        output_path = f"results/{image_file}"
        sadtalker.generate(
            source_image=os.path.join(image_dir, image_file),
            driven_audio=audio_file,
            preprocess="full"
        )
```

## Interface web

### Lancer la démo web

```bash
python app.py
```

Puis ouvrir dans le navigateur http://localhost:8888

### Fonctionnalités de l'interface web

1. **Téléversement d'image** : Glisser-déposer ou sélectionner une image portrait
2. **Téléversement audio** : Sélectionner un fichier audio (WAV/MP3)
3. **Aperçu** : Prévisualiser l'image source et l'audio
4. **Paramètres** : Ajuster la pose, l'expression, l'améliorationur
5. **Générer** : Créer une vidéo en un clic
6.Télécharger** : Enregistrer la vidéo générée

### Contrôles de l'interface web

| Contrôle | Description |
|----------|-------------|
| Source Image | Téléverser une photo portrait |
| Driven Audio | Téléverser un audio vocal |
| Preprocess | Choisir le mode de prétraitement |
| Pose Style | Sélectionner le style d'animation de pose |
| Enhancer | Sélectionner l'améliorationur de qualité faciale |
| Generate Button | Démarrer la génération vidéo |

## Améliorateurs faciaux

### Améliorateurs disponibles

| Améliorateur | Qualité | Vitesse | VRAM |
|--------------|---------|---------|------|
| Aucun | Basique | Rapide | Faible |
| gfpgan | Bonne | Moyenne | Moyen |
| RestoreFormer | Très bonne | Lente | Élevé |
| CodeFormer | Très bonne | Lente | Élevé |

### Recommandation

- **VRAM faible** : Pas d'améliorationur ou gfpgan
- **Équilibré** : gfpgan
- **Meilleure qualité** : RestoreFormer ou CodeFormer

## Modes de prétraitement

| Mode | Description | Cas d'utilisation |
|------|-------------|-------------------|
| crop | Recadrer le visage au centre | Traitement rapide |
| resize | Redimensionner à la cible | Arrière-plans simples |
| full | Pipeline complet | Meilleurs résultats |

## Exigences d'entrée

### Exigences d'image

- Format : JPG, PNG
- Taille : 512x512 ou plus recommandé
- Visage : De face, traits nets
- Arrière-plan : Simple préférable

### Exigences audio

- Format : WAV, MP3
- Durée : 1-60 secondes
- Fréquence d'échantillonnage : 16000-48000 Hz
- Discours : Audio clair avec un bruit minimal

## Sortie

### Format vidéo

- Format : MP4
- Codec : H.264
- Résolution : 256x256 ou 512x512
- IPS : 25
- Débit : 2-5 Mbps

### Répertoire de sortie

Les résultats sont enregistrés dans le répertoire spécifié :
```
results/
├── video.mp4          # Vidéo générée
├── video_idx.mp4     # Avec index (si plusieurs)
└── (fichiers temporaires)
```

## Dépannage

### Vidéo trop sombre/lumineuse

**Cause** : Inadéquation de l'éclairage entre l'entraînement et l'entrée

**Solutions** :
- Ajuster le paramètre expression_scale (0.8-1.2)
- Utiliser une image source de meilleure qualité
- Essayer un améliorateur différent

### Lèvres non synchronisées

**Cause** : Problèmes de qualité ou d'alignement audio

**Solutions** :
- Utiliser un audio de haute qualité
- S'assurer que l'audio contient un discours clair
- Vérifier la synchronisation audio-vidéo
- Couper l'audio pour correspondre à la durée vidéo

### Distorsion faciale

**Cause** : Entrée de basse qualité ou inhabituelle

**Solutions** :
- Utiliser une image de résolution plus élevée (512)
- Essayer un autre mode de prétraitement
- Utiliser un améliorateur facial
- S'assurer que le visage est clairement visible

### Traitement lent

**Solutions** :
- Réduire la taille du batch
- Baisser la résolution (--size 256)
- Désactiver l'amélioreur
- Utiliser un prétraitement plus rapide (crop)

### Mémoire GPU épuisée

**Solutions** :
- Réduire batch_size à 1
- Utiliser une taille d'image plus petite
- Fermer les autres applications GPU
- Activer le déchargement CPU

## Conseils de performance

### Traitement plus rapide

1. Utiliser `--preprocess crop`
2. Définir `--size 256`
3. Désactiver l'amélioreur
4. Réduire la taille du batch

### Meilleure qualité

1. Utiliser `--size 512`
2. Activer `--enhancer gfpgan`
3. Utiliser `--preprocess full`
4. Ajuster `--expression_scale`

### Économiser le VRAM

1. Traiter un par un
2. Utiliser des modèles plus petits
3. Désactiver les fonctionnalités inutiles

## Exemples d'intégration

### API Python Flask

```python
from flask import Flask, request, send_file
from inference import SadTalker
import tempfile

app = Flask(__name__)
sadtalker = SadTalker()

@app.route('/generate', methods=['POST'])
def generate():
    image = request.files['image']
    audio = request.files['audio']
    
    with tempfile.NamedTemporaryFile(suffix='.jpg', delete=False) as img:
        image.save(img.name)
    
    with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as aud:
        audio.save(aud.name)
    
    video_path = sadtalker.generate(
        source_image=img.name,
        driven_audio=aud.name,
        preprocess="full"
    )
    
    return send_file(video_path, mimetype='video/mp4')
```

## Liens connexes

- [GitHub](https://github.com/OpenTalker/SadTalker)
- [HuggingFace](https://huggingface.co/spaces/fffilo/SadTalker)
- [Article](https://arxiv.org/abs/2303.17550)
- [Modèles](https://github.com/OpenTalker/SadTalker/releases)
