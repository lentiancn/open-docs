# SadTalker Installation Guide

SadTalker is an AI project for generating realistic talking head videos from a single image and audio input.

## System Requirements

### Hardware Requirements

| Component | Minimum | Recommended |
|-----------|---------|-------------|
| GPU | NVIDIA 6GB VRAM | NVIDIA 16GB VRAM |
| RAM | 8GB | 32GB |
| Storage | 20GB free | 50GB free |
| OS | Ubuntu 18.04+, Windows 10+, macOS 11+ | Ubuntu 20.04+ |

### Software Requirements

| Software | Version | Notes |
|----------|---------|-------|
| Python | 3.8 - 3.10 | 3.9 recommended |
| CUDA | 11.7+ | For GPU acceleration |
| cuDNN | 8.5+ | Required for CUDA |
| ffmpeg | Latest | For video processing |

## Installation on Linux/Ubuntu

### Step 1: Install System Dependencies

```bash
# Update system
sudo apt update && sudo apt upgrade -y

# Install Python and development tools
sudo apt install python3.9 python3-pip python3-venv git wget curl

# Install system libraries
sudo apt install libgl1-mesa-glx libglib2.0-0 libsm6 libxext6 libxrender-dev libgomp1

# Install ffmpeg
sudo apt install ffmpeg

# Install NVIDIA drivers (if not installed)
sudo apt install nvidia-driver-525
```

### Step 2: Install CUDA (if needed)

```bash
# Download and install CUDA 11.8
wget https://developer.download.nvidia.com/compute/cuda/11.8.0/local_installers/cuda_11.8.0_520.61.05_linux.run
sudo sh cuda_11.8.0_520.61.05_linux.run
```

### Step 3: Clone Repository

```bash
git clone https://github.com/OpenTalker/SadTalker.git
cd SadTalker
```

### Step 4: Create Virtual Environment

```bash
python3.9 -m venv venv
source venv/bin/activate

# Verify Python version
python --version
```

### Step 5: Install PyTorch

```bash
# For CUDA 11.8
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

# Verify installation
python -c "import torch; print(torch.cuda.is_available())"
```

### Step 6: Install Dependencies

```bash
pip install -r requirements.txt

# Install additional dependencies
pip install numpy opencv-python librosa soundfile
```

### Step 7: Download Models

```bash
# Create models directory
mkdir -p checkpoints

# Download models (automatic)
bash scripts/download_models.sh

# Or manually download from releases
# Place models in checkpoints/ directory
```

## Installation on Windows

### Step 1: Install Python

1. Download Python 3.9 from python.org
2. During installation, check "Add Python to PATH"
3. Verify: `python --version`

### Step 2: Install CUDA

1. Download CUDA 11.8 from NVIDIA website
2. Install with default settings
3. Download and install cuDNN 8.9

### Step 3: Clone and Setup

```powershell
git clone https://github.com/OpenTalker/SadTalker.git
cd SadTalker

python -m venv venv
venv\Scripts\activate
```

### Step 4: Install Dependencies

```powershell
# Install PyTorch with CUDA support
pip install torch==2.0.1 torchvision==0.15.2 --index-url https://download.pytorch.org/whl/cu118

pip install -r requirements.txt
```

### Step 5: Download Models

Download models from the GitHub releases page and place in `checkpoints/` folder.

## Installation on macOS

### Step 1: Install Dependencies

```bash
# Install Homebrew (if not installed)
/bin/bash -c "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)"

# Install Python and ffmpeg
brew install python@3.9 ffmpeg git
```

### Step 2: Setup

```bash
git clone https://github.com/OpenTalker/SadTalker.git
cd SadTalker

python3.9 -m venv venv
source venv/bin/activate

# Install PyTorch (CPU only for macOS)
pip install torch==2.0.1 torchvision==0.15.2

pip install -r requirements.txt
```

Note: macOS runs in CPU-only mode. GPU acceleration is not available.

## Docker Installation

### Using Docker

```bash
# Pull image
docker pull ghcr.io/opentalker/sadtalker:latest

# Run with GPU support
docker run --gpus all -v $(pwd):/workspace -p 8888:8888 ghcr.io/opentalker/sadtalker:latest
```

### Using Docker Compose

```yaml
version: '3.8'
services:
  sadtalker:
    image: ghcr.io/opentalker/sadtalker:latest
    volumes:
      - ./workspace:/workspace
    ports:
      - "8888:8888"
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## Verify Installation

```bash
# Test basic functionality
python inference.py --help

# Should display all available options
```

## Common Issues

### CUDA Out of Memory

**Solution:**
- Reduce batch size: `--batch_size 1`
- Use lower resolution: `--size 256`
- Enable model offloading
- Close other GPU applications

### Missing Libraries (Windows)

**Solution:**
- Install Visual C++ Redistributable 2015-2022
- Add CUDA to system PATH

### Model Download Failures

**Solution:**
- Use VPN or proxy
- Download manually from GitHub releases
- Check network connection

### ffmpeg Not Found

**Solution:**
- Linux: `sudo apt install ffmpeg`
- Windows: Add ffmpeg to PATH
- macOS: `brew install ffmpeg`

## Related Links

- [GitHub Repository](https://github.com/OpenTalker/SadTalker)
- [HuggingFace Demo](https://huggingface.co/spaces/fffilo/SadTalker)
- [Paper](https://arxiv.org/abs/2303.17550)
- [Models Download](https://github.com/OpenTalker/SadTalker/releases)
